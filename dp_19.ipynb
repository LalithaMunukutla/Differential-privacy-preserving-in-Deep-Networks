{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3281,"status":"ok","timestamp":1639718735291,"user":{"displayName":"Sri Lalitha","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gisb-ak46FNIdm645NllKqiVAF9jpxvEIpX0fyu0Q=s64","userId":"01193405302123610620"},"user_tz":-330},"id":"Jp1yiuyr6-_1","outputId":"a48b307d-a2e1-4db9-8702-cd73a01e5a80"},"outputs":[{"output_type":"stream","name":"stdout","text":["WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/compat/v2_compat.py:111: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","non-resource variables are not supported in the long term\n"]}],"source":["import timeit\n","import numpy as np\n","import tensorflow.compat.v1 as tf\n","tf.disable_v2_behavior()\n","from __future__ import absolute_import\n","from __future__ import division\n","from __future__ import print_function\n","import gzip\n","import os\n","from six.moves import urllib\n","from six.moves import xrange \n","import math\n","from tensorflow.python.framework import ops;\n","import argparse;\n","import pickle;\n","from datetime import datetime\n","from tensorflow.python.framework import constant_op\n","from tensorflow.python.framework import dtypes\n","from tensorflow.python.framework import ops\n","from tensorflow.python.ops import array_ops\n","from tensorflow.python.ops import candidate_sampling_ops\n","from tensorflow.python.ops import embedding_ops\n","from tensorflow.python.ops import gen_nn_ops\n","from tensorflow.python.ops import math_ops\n","from tensorflow.python.ops import nn_ops\n","from tensorflow.python.ops import sparse_ops\n","from tensorflow.python.ops import variables\n","import time\n","import matplotlib.pyplot as plt"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":515,"status":"ok","timestamp":1639718754669,"user":{"displayName":"Sri Lalitha","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gisb-ak46FNIdm645NllKqiVAF9jpxvEIpX0fyu0Q=s64","userId":"01193405302123610620"},"user_tz":-330},"id":"G25PaSbL7R2M"},"outputs":[],"source":["SOURCE_URL = 'http://yann.lecun.com/exdb/mnist/'\n","def maybe_download(filename, work_directory):\n","  \"\"\"Download the data from Yann's website, unless it's already here.\"\"\"\n","  if not os.path.exists(work_directory):\n","    os.mkdir(work_directory)\n","  filepath = os.path.join(work_directory, filename)\n","  if not os.path.exists(filepath):\n","    filepath, _ = urllib.request.urlretrieve(SOURCE_URL + filename, filepath)\n","    statinfo = os.stat(filepath)\n","    print('Successfully downloaded', filename, statinfo.st_size, 'bytes.')\n","  return filepath\n","def _read32(bytestream):\n","  dt = np.dtype(np.uint32).newbyteorder('>')\n","  return np.frombuffer(bytestream.read(4), dtype=dt)[0]\n","def extract_images(filename):\n","  \"\"\"Extract the images into a 4D uint8 numpy array [index, y, x, depth].\"\"\"\n","  print('Extracting', filename)\n","  with gzip.open(filename) as bytestream:\n","    magic = _read32(bytestream)\n","    if magic != 2051:\n","      raise ValueError('Invalid magic number %d in MNIST image file: %s' %(magic, filename))\n","    num_images = _read32(bytestream)\n","    rows = _read32(bytestream)\n","    cols = _read32(bytestream)\n","    buf = bytestream.read(rows * cols * num_images)\n","    data = np.frombuffer(buf, dtype=np.uint8)\n","    data = data.reshape(num_images, rows, cols, 1)\n","    return data\n","def dense_to_one_hot(labels_dense, num_classes=10):\n","  \"\"\"Convert class labels from scalars to one-hot vectors.\"\"\"\n","  num_labels = labels_dense.shape[0]\n","  index_offset = np.arange(num_labels) * num_classes\n","  labels_one_hot = np.zeros((num_labels, num_classes))\n","  labels_one_hot.flat[index_offset + labels_dense.ravel()] = 1\n","  return labels_one_hot\n","def extract_labels(filename, one_hot=False):\n","  \"\"\"Extract the labels into a 1D uint8 numpy array [index].\"\"\"\n","  print('Extracting', filename)\n","  with gzip.open(filename) as bytestream:\n","    magic = _read32(bytestream)\n","    if magic != 2049:\n","      raise ValueError('Invalid magic number %d in MNIST label file: %s' %(magic, filename))\n","    num_items = _read32(bytestream)\n","    buf = bytestream.read(num_items)\n","    labels = np.frombuffer(buf, dtype=np.uint8)\n","    if one_hot:\n","      return dense_to_one_hot(labels)\n","    return labels\n","class DataSet(object):\n","  def __init__(self, images, labels, fake_data=False):\n","    if fake_data:\n","      self._num_examples = 10000\n","    else:\n","      assert images.shape[0] == labels.shape[0], (\"images.shape: %s labels.shape: %s\" % (images.shape,labels.shape))\n","      self._num_examples = images.shape[0]\n","      # Convert shape from [num examples, rows, columns, depth]\n","      # to [num examples, rows*columns] (assuming depth == 1)\n","      assert images.shape[3] == 1\n","      images = images.reshape(images.shape[0],images.shape[1] * images.shape[2])\n","      # Convert from [0, 255] -> [0.0, 1.0].\n","      images = images.astype(np.float32)\n","      images = np.multiply(images, 1.0 / 255.0)\n","    self._images = images\n","    self._labels = labels\n","    self._epochs_completed = 0\n","    self._index_in_epoch = 0\n","  @property\n","  def images(self):\n","    return self._images\n","  @property\n","  def labels(self):\n","    return self._labels\n","  @property\n","  def num_examples(self):\n","    return self._num_examples\n","  @property\n","  def epochs_completed(self):\n","    return self._epochs_completed\n","  def next_batch(self, batch_size, fake_data=False):\n","    \"\"\"Return the next `batch_size` examples from this data set.\"\"\"\n","    if fake_data:\n","      fake_image = [1.0 for _ in xrange(784)]\n","      fake_label = 0\n","      return [fake_image for _ in xrange(batch_size)], [\n","          fake_label for _ in xrange(batch_size)]\n","    start = self._index_in_epoch\n","    self._index_in_epoch += batch_size\n","    if self._index_in_epoch > self._num_examples:\n","      # Finished epoch\n","      self._epochs_completed += 1\n","      # Shuffle the data\n","      perm = np.arange(self._num_examples)\n","      np.random.shuffle(perm)\n","      self._images = self._images[perm]\n","      self._labels = self._labels[perm]\n","      # Start next epoch\n","      start = 0\n","      self._index_in_epoch = batch_size\n","      assert batch_size <= self._num_examples\n","    end = self._index_in_epoch\n","    return self._images[start:end], self._labels[start:end]\n","def read_data_sets(train_dir, fake_data=False, one_hot=False):\n","  class DataSets(object):\n","    pass\n","  data_sets = DataSets()\n","  if fake_data:\n","    data_sets.train = DataSet([], [], fake_data=True)\n","    data_sets.validation = DataSet([], [], fake_data=True)\n","    data_sets.test = DataSet([], [], fake_data=True)\n","    return data_sets\n","  TRAIN_IMAGES = 'train-images-idx3-ubyte.gz'\n","  TRAIN_LABELS = 'train-labels-idx1-ubyte.gz'\n","  TEST_IMAGES = 't10k-images-idx3-ubyte.gz'\n","  TEST_LABELS = 't10k-labels-idx1-ubyte.gz'\n","  VALIDATION_SIZE = 5000\n","  local_file = maybe_download(TRAIN_IMAGES, train_dir)\n","  train_images = extract_images(local_file)\n","  local_file = maybe_download(TRAIN_LABELS, train_dir)\n","  train_labels = extract_labels(local_file, one_hot=one_hot)\n","  local_file = maybe_download(TEST_IMAGES, train_dir)\n","  test_images = extract_images(local_file)\n","  local_file = maybe_download(TEST_LABELS, train_dir)\n","  test_labels = extract_labels(local_file, one_hot=one_hot)\n","  validation_images = train_images[:VALIDATION_SIZE]\n","  validation_labels = train_labels[:VALIDATION_SIZE]\n","  train_images = train_images[VALIDATION_SIZE:]\n","  train_labels = train_labels[VALIDATION_SIZE:]\n","  data_sets.train = DataSet(train_images, train_labels)\n","  data_sets.validation = DataSet(validation_images, validation_labels)\n","  data_sets.test = DataSet(test_images, test_labels)\n","  return data_sets"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CUL0-VbO7gAX"},"outputs":[],"source":[""]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":499,"status":"ok","timestamp":1639718761020,"user":{"displayName":"Sri Lalitha","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gisb-ak46FNIdm645NllKqiVAF9jpxvEIpX0fyu0Q=s64","userId":"01193405302123610620"},"user_tz":-330},"id":"Z9kf-ftV_AVK"},"outputs":[],"source":["class LogisticRegression(object):\n","    '''Multi-class logistic regression class'''\n","    def __init__(self, inpt, n_in, n_out):\n","        '''\n","        inpt: tf.Tensor, (one minibatch) [None, n_in]\n","        n_in: int, number of input units\n","        n_out: int, number of output units\n","        '''\n","        # weight\n","        self.W = tf.Variable(tf.zeros([n_in, n_out], dtype=tf.float32))\n","        # bias\n","        self.b = tf.Variable(tf.zeros([n_out]), dtype=tf.float32)\n","        # activation output\n","        self.output = tf.nn.softmax(tf.matmul(inpt, self.W) + self.b)\n","        # prediction\n","        self.y_pred = tf.argmax(self.output, axis=1)\n","        # keep track of variables\n","        self.params = [self.W, self.b]\n","\n","    def cost(self, y):\n","        '''\n","        y: tf.Tensor, the target of the input\n","        '''\n","        # cross_entropy\n","        return -tf.reduce_mean(tf.reduce_sum(y * tf.log(self.output), axis=1))\n","\n","    def accuarcy(self, y):\n","        '''errors'''\n","        correct_pred = tf.equal(self.y_pred, tf.argmax(y, axis=1))\n","        return tf.reduce_mean(tf.cast(correct_pred, tf.float32))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Nq3ykxaT7t1E"},"outputs":[],"source":[""]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":512,"status":"ok","timestamp":1639718764090,"user":{"displayName":"Sri Lalitha","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gisb-ak46FNIdm645NllKqiVAF9jpxvEIpX0fyu0Q=s64","userId":"01193405302123610620"},"user_tz":-330},"id":"EBOaL7Sn_H0V"},"outputs":[],"source":["class dpLogisticRegression(object):\n","    '''Multi-class logistic regression class'''\n","    def __init__(self, inpt, n_in, n_out, LaplaceNoise):\n","        '''\n","        inpt: tf.Tensor, (one minibatch) [None, n_in]\n","        n_in: int, number of input units\n","        n_out: int, number of output units\n","        LaplaceNoise: Laplace noise\n","        '''\n","        # weight\n","        self.W = tf.Variable(tf.truncated_normal([n_in, n_out], stddev=0.1), dtype=tf.float32, name=\"W\")\n","        # bias\n","        self.b = tf.Variable(tf.zeros([n_out]), dtype=tf.float32)\n","        # activation output\n","        inpt = tf.clip_by_value(inpt, 0, 1) # hidden neurons must be bounded in [0, 1], sigmoid activation function does not need this bound\n","        inpt += LaplaceNoise;\n","        self.output = tf.matmul(inpt, self.W) + self.b\n","        # prediction\n","        self.y_pred = tf.argmax(self.output, axis=1)\n","        # keep track of variables\n","        self.params = [self.W, self.b]\n","    \n","    def cost(self, y):\n","        zeros = array_ops.zeros_like(self.output, dtype=self.output.dtype)\n","        cond = (self.output >= zeros)\n","        relu_logits = array_ops.where(cond, self.output, zeros)\n","        neg_abs_logits = array_ops.where(cond, -self.output, self.output)\n","        #Taylor = math_ops.add(relu_logits - y_conv * y_, math_ops.log1p(math_ops.exp(neg_abs_logits)))\n","        Taylor = math_ops.add(relu_logits - self.output * y, math.log(2.0) + 0.5*neg_abs_logits + 1.0/8.0*neg_abs_logits**2)\n","        return Taylor\n","    \n","    def accuarcy(self, y):\n","        '''prediction accuracy'''\n","        correct_pred = tf.equal(self.y_pred, tf.argmax(y, axis=1))\n","        return tf.reduce_mean(tf.cast(correct_pred, tf.float32))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jl0Fqo7d8EY4"},"outputs":[],"source":[""]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1639718766137,"user":{"displayName":"Sri Lalitha","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gisb-ak46FNIdm645NllKqiVAF9jpxvEIpX0fyu0Q=s64","userId":"01193405302123610620"},"user_tz":-330},"id":"b3X2HDdC_SIw"},"outputs":[],"source":["class EncLayer(object):\n","    '''Typical convolutional layer of MLP'''\n","    def __init__(self, inpt, n_filter_in, n_filter_out, filter_size, W=None, b=None, activation=tf.nn.sigmoid):\n","        '''\n","        :param inpt: input for the layer, i.e., images\n","        :param n_filter_in: the number of input feature maps\n","        :param n_filter_out: the number of input feature maps\n","        :param filter_size: the dimension of convolutional filter [filter_size, filter_size]\n","        '''\n","        # Initialize parameters: W and b\n","        if W is None:\n","            W = tf.Variable(tf.truncated_normal([filter_size, filter_size, n_filter_in, n_filter_out], stddev=0.1), dtype=tf.float32, name=\"W\")\n","        if b is None:\n","            b = tf.Variable(tf.zeros([n_filter_out]), dtype=tf.float32, name=\"b\")\n","        self.W = W\n","        self.b = b\n","        self.input = inpt;\n","        # the output\n","        sum_W = tf.add(tf.nn.conv2d(inpt, self.W, strides=[1, 2, 2, 1], padding='SAME'), self.b)\n","        self.output = activation(sum_W) if activation is not None else sum_W\n","        # the input's shape\n","        self.inputShape = inpt.get_shape().as_list()\n","        # params of the layers\n","        self.params = [self.W, self.b]\n","            \n","    # define the Chebyshev Polinomial approximation\n","    def Chebyshev(self, x):\n","        return (-5*x**7 + 21*x**5 - 35*x**3 + 35*x + 16)/(2.0**5) # L = 7\n","        #return (-x**3 + 3*x + 2)/(2.0**2) # L = 3\n","        #return (5*x**5 + 2*x**4 - 14*x**3 - 4*x**2 + 17*x + 10)/(2.0) # L = 5\n","        #return (-x**2 + 2*x + 3)/(2.0**2) # L = 2\n","    \n","    def dpChebyshev(self, x, Delta, epsilon, batch_size):\n","        coefficients = [-5.0, 21.0, -35.0, 35.0, 16.0] # L = 7\n","        #coefficients = [-1.0, 3.0, 2.0] # L = 3\n","        #coefficients = [-1.0, 2.0, 3.0] # L = 2\n","        #coefficients = [5.0, 2.0, -14.0, -4.0, 17.0, 10.0] # L = 5\n","        for i in range(0, len(coefficients)):\n","            perturbFM = np.random.laplace(0.0, 1.0/(epsilon*batch_size), 1).astype(np.float32);\n","            perturbFM = tf.multiply(perturbFM, Delta);\n","            coefficients[i] += perturbFM;\n","        return (tf.multiply(coefficients[0], x**7) + tf.multiply(coefficients[1], x**5) + tf.multiply(coefficients[2], x**3) + tf.multiply(coefficients[3], x**1) + coefficients[4])/(2.0**5) # L = 7\n","        #return (tf.multiply(coefficients[0], x**3) + tf.multiply(coefficients[1], x) + coefficients[2])/(2.0**2) # L = 3\n","        #return (tf.multiply(coefficients[0], x**2) + tf.multiply(coefficients[1], x) + coefficients[2])/(2.0**2) # L = 2\n","        #return (tf.multiply(coefficients[0], x**5) + tf.multiply(coefficients[1], x**4) + tf.multiply(coefficients[2], x**3) + tf.multiply(coefficients[3], x**2) + tf.multiply(coefficients[4], x**1) + coefficients[5])/(2.0) # L = 5\n","    \n","    # sampling hidden neurons given visible neurons\n","    def propup(self, v):\n","        '''Compute the sigmoid activation for hidden units given visible units'''\n","        h = tf.add(tf.nn.conv2d(v, self.W, strides=[1, 2, 2, 1], padding='SAME'), self.b)\n","        # Get the max value of hidden neurons\n","        max = tf.reduce_max(h)\n","        # Normalization so that h will satisfy the Riemann integrable condition on [−1, 1]\n","        h = h/max;\n","        return tf.clip_by_value(self.Chebyshev(h), 0.0, 1.0) # values of hidden neurons must be bounded [0, 1]\n","\n","    # differentially private hidden terms given visible neurons\n","    def dp_propup(self, v, Delta, epsilon, batch_size):\n","        '''Compute the differentially private activation for hidden terms given visible units'''\n","        h = tf.add(tf.nn.conv2d(v, self.W, strides=[1, 2, 2, 1], padding='SAME'), self.b)\n","        max = tf.reduce_max(h)\n","        h = h/max;\n","        # hidden neurons have to be bounded in [0, 1] after the perturbation\n","        Chebyshev_h = tf.clip_by_value(self.dpChebyshev(h, Delta, epsilon, batch_size), 0.0, 1.0)\n","\n","        return Chebyshev_h # return perturbed approximated polinomial coefficients h\n","    \n","    # transpose of convolutional RBM given hidden neurons, this is use for convolutional auto-encoder\n","    def decode(self, xShape, propup, activation=tf.nn.sigmoid):\n","        rc_input = activation(tf.add(tf.nn.conv2d_transpose(propup, self.W,\n","                    tf.stack([xShape, self.inputShape[1], self.inputShape[2], self.inputShape[3]]),\n","                    strides=[1, 2, 2, 1], padding='SAME'), self.b))\n","        return rc_input\n","    \n","    # reconstruct visible units from convolutional feature maps\n","    def decode2(self, xShape, propup, activation=tf.nn.sigmoid):\n","        # upsampling given hidden feature maps to obtain input's size feature maps. This step can be considered an actual deconvolution\n","        upsample3 = tf.image.resize_images(propup, size=(self.inputShape[1],self.inputShape[2]), method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n","        # reconstruct the original inputs\n","        rc_input = activation(tf.nn.conv2d(input=upsample3, filter=tf.transpose(self.W, perm=[1, 0, 3, 2]), strides=[1, 1, 1, 1], padding='SAME'))\n","        ###\n","        return rc_input\n","    \n","    # get pre-training objective function, this is use for convolutional auto-encoder\n","    def get_train_ops(self, xShape, learning_rate=0.1):\n","        propup = self.propup(self.input)\n","        rc_v = self.decode(xShape, propup, activation=tf.nn.sigmoid);\n","        self.cost = tf.reduce_sum(tf.square(rc_v - self.input))\n","        optimizer = tf.train.AdamOptimizer(learning_rate).minimize(self.cost, var_list=self.params)\n","        return optimizer\n","    \n","    # get differentially private pre-training energy function for convolutional RBM\n","    def get_train_ops2(self, xShape, Delta, epsilon = 0.25, batch_size = 3600, learning_rate=0.1):\n","        # compute h terms\n","        propup = self.dp_propup(self.input, Delta, epsilon, batch_size)\n","        # reconstruct v terms\n","        rc_v = self.decode2(xShape, propup, activation=tf.nn.sigmoid);\n","        # reconstruct h terms\n","        rc_propup = self.dp_propup(rc_v, Delta, epsilon, batch_size)\n","        # minimize the differentially private mean between the two energy functions: (1) contructed from the original input, (2) constructed from the reconstructed input. In other words, we use CD-1 to minimize the energy function.\n","        self.cost = tf.reduce_mean(tf.abs(rc_propup - propup)) + tf.reduce_mean(tf.abs(rc_v - self.input))\n","        # define AdamOptimizer optimization\n","        optimizer = tf.train.AdamOptimizer(learning_rate).minimize(self.cost, var_list=self.params)\n","        return optimizer"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_bmu1hIO8G2k"},"outputs":[],"source":[""]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1639718767980,"user":{"displayName":"Sri Lalitha","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gisb-ak46FNIdm645NllKqiVAF9jpxvEIpX0fyu0Q=s64","userId":"01193405302123610620"},"user_tz":-330},"id":"Gy4n-PoY_h4H"},"outputs":[],"source":["class ConvLayer(object):\n","    '''Typical convolutional layer of MLP'''\n","    def __init__(self, inpt, filter_size, n_in, n_out, W=None, b=None, activation=tf.nn.sigmoid):\n","        '''\n","        :param inpt: input for the layer, i.e., images\n","        :param n_in: the number of input units\n","        :param n_out: the number of output units\n","        '''\n","        if W is None:\n","            W = tf.Variable(tf.truncated_normal([filter_size, filter_size, n_in, n_out], stddev=0.1), dtype=tf.float32, name=\"W\")\n","        if b is None:\n","            b = tf.Variable(tf.zeros([n_out]), dtype=tf.float32, name=\"b\")\n","\n","        self.W = W\n","        self.b = b\n","        # the output\n","        sum_W = tf.add(tf.nn.conv2d(inpt, self.W, strides=[1, 2, 2, 1], padding='SAME'), self.b)\n","        self.output = activation(sum_W) if activation is not None else sum_W\n","        # params\n","        self.params = [self.W, self.b]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CH2dB_uv8Mkm"},"outputs":[],"source":[""]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":416,"status":"ok","timestamp":1639718770748,"user":{"displayName":"Sri Lalitha","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gisb-ak46FNIdm645NllKqiVAF9jpxvEIpX0fyu0Q=s64","userId":"01193405302123610620"},"user_tz":-330},"id":"nLWveHgxJQvc"},"outputs":[],"source":["class ConvFlat(object):\n","    '''Transforming layer from a convolutional layer to a fully connected layer'''\n","    def __init__(self, inpt, xShape, n_out, activation=tf.nn.sigmoid):\n","        '''\n","        inpt: tf.Tensor, (one minibatch) [None, n_in]\n","        xShape: the first dimention of the input, i.e., used to access the batch_size\n","        n_out: int, number of output units\n","        '''\n","        # Initialize parameters W and b\n","        shape = inpt.get_shape().as_list()\n","        n_in = shape[1]*shape[2]*shape[3]\n","        # weight\n","        self.W = tf.Variable(tf.truncated_normal([n_in, n_out], stddev=0.1), dtype=tf.float32, name=\"W\")\n","        # bias\n","        self.b = tf.Variable(tf.zeros([n_out]), dtype=tf.float32)\n","        ###\n","        # Compute the output\n","        h = tf.reshape(inpt, tf.stack([xShape, n_in]))\n","        sum_W = tf.matmul(h, self.W) + self.b\n","        # Applying normalization for the flat connected layer\n","        batch_mean2, batch_var2 = tf.nn.moments(sum_W,[0])\n","        scale2 = tf.Variable(tf.ones([n_out]))\n","        beta2 = tf.Variable(tf.zeros([n_out]))\n","        BN_norm = tf.nn.batch_normalization(sum_W,batch_mean2,batch_var2,beta2,scale2,1e-3)\n","        ###\n","        self.output = activation(BN_norm) if activation is not None else BN_norm\n","        #####\n","        # keep track of variables\n","        self.params = [self.W, self.b]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jfmZWdc_8PP0"},"outputs":[],"source":[""]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1639718772446,"user":{"displayName":"Sri Lalitha","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gisb-ak46FNIdm645NllKqiVAF9jpxvEIpX0fyu0Q=s64","userId":"01193405302123610620"},"user_tz":-330},"id":"bGDqmTICJVw4"},"outputs":[],"source":["class HiddenLayer(object):\n","    '''Typical hidden layer of MLP'''\n","    def __init__(self, inpt, n_in, n_out, activation=tf.nn.sigmoid):\n","        '''\n","        inpt: tf.Tensor, shape [n_examples, n_in]\n","        n_in: int, the dimensionality of input\n","        n_out: int, number of hidden units\n","        W, b: tf.Tensor, weight and bias\n","        activation: tf.op, activation function\n","        '''\n","        # weight\n","        self.W = tf.Variable(tf.truncated_normal([n_in, n_out], stddev=0.1), dtype=tf.float32, name=\"W\")\n","        # bias\n","        self.b = tf.Variable(tf.zeros([n_out]), dtype=tf.float32)\n","        self.input = inpt;\n","        # shape\n","        self.n_in = n_in;\n","        self.n_out = n_out;\n","        # the output\n","        sum_W = tf.matmul(inpt, self.W) + self.b\n","        self.output = activation(sum_W) if activation is not None else sum_W\n","        # params\n","        self.params = [self.W, self.b]\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9i0voy7H8S6R"},"outputs":[],"source":[""]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1639718774332,"user":{"displayName":"Sri Lalitha","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gisb-ak46FNIdm645NllKqiVAF9jpxvEIpX0fyu0Q=s64","userId":"01193405302123610620"},"user_tz":-330},"id":"eyjHrVFAJbaG"},"outputs":[],"source":["class MLP(object):\n","    '''Multi-layer perceptron class'''\n","    def __init__(self, inpt, n_in, n_hidden, n_out):\n","        '''\n","        inpt: tf.Tensor, shape [n_examples, n_in]\n","        n_in: int, the dimensionality of input\n","        n_hidden: int, number of hidden units\n","        n_out: int, number of output units\n","        '''\n","        # hidden layer\n","        self.hiddenLayer = HiddenLayer(inpt, n_in=n_in, n_out=n_hidden)\n","        # output layer (logistic layer)\n","        self.outputLayer = LogisticRegression(self.hiddenLayer.output, n_in=n_hidden,\n","                                              n_out=n_out)\n","        # L1 norm\n","        self.L1 = tf.reduce_sum(tf.abs(self.hiddenLayer.W)) + \\\n","                  tf.reduce_sum(tf.abs(self.outputLayer.W))\n","        # L2 norm\n","        self.L2 = tf.reduce_sum(tf.square(self.hiddenLayer.W)) + \\\n","                  tf.reduce_sum(tf.square(self.outputLayer.W))\n","        # cross_entropy cost function\n","        self.cost = self.outputLayer.cost\n","        # accuracy function\n","        self.accuracy = self.outputLayer.accuarcy\n","\n","        # params\n","        self.params = self.hiddenLayer.params + self.outputLayer.params\n","        # keep track of input\n","        self.input = inpt"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"B4efUzK78X6k"},"outputs":[],"source":[""]},{"cell_type":"markdown","metadata":{"id":"zro_TOll_hTe"},"source":["epochs vs accuracy (training set)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6alVKfvnA7Q4"},"outputs":[],"source":[""]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":1171,"status":"ok","timestamp":1639718937249,"user":{"displayName":"Sri Lalitha","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gisb-ak46FNIdm645NllKqiVAF9jpxvEIpX0fyu0Q=s64","userId":"01193405302123610620"},"user_tz":-330},"id":"vOppgr5Vzf_b"},"outputs":[],"source":["os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n","os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n","import matplotlib.pyplot as plt\n","#plt.style.use('default')\n","#fig,ax= plt.subplots()\n","x_a=[]\n","y_a=[]\n","class pCDBN(object):\n","    '''\n","    An implement of differentially private convolutional deep belief network\n","    '''\n","    def __init__(self, n_in=784, n_out=10, filter_size = 5, hidden_layers_sizes=[10, 10, 25], epsilon = 0.25, _batch_size = 3600, finetuneLR = 0.01):\n","        '''\n","        :param n_in: int, the dimension of input\n","        :param n_out: int, the dimension of output\n","        :param filter_size: the dimension of convolutional filter [filter_size, filter_size]\n","        :param hidden_layers_sizes: list or tuple, the number of convolutional feature maps, the last item will be the number of hidden neurons in the last hidden layer\n","        :param epsilon: privacy budget epsilon\n","        :param _batch_size: the batch size\n","        :param finetuneLR: fine tunning learning rate\n","        '''\n","        # Number of layers\n","        assert len(hidden_layers_sizes) > 0\n","        self.n_layers = len(hidden_layers_sizes)\n","        self.layers = []    # convolutional and hidden layers\n","        self.params = []       # keep track of params for training\n","        self.last_n_in = hidden_layers_sizes[-1] # the number of hidden neurons in the last hidden layer\n","        self.pretrain_ops = []; # list of pretrain objective functions for convolutional layers\n","        self.epsilon = epsilon; # privacy budget epsilon epsilon\n","        self.batch_size = _batch_size; # batch size\n","\n","        # Define the input, output, Laplace noise for the output layer, and Delta for the pretrain convolutional layers\n","        self.x = tf.placeholder(tf.float32, shape=[None, n_in], name='x')\n","        # ensure 2-d is converted to square tensor.\n","        if len(self.x.get_shape()) == 2:\n","            x_dim = np.sqrt(self.x.get_shape().as_list()[1])\n","            if x_dim != int(x_dim):\n","                raise ValueError('Unsupported input dimensions')\n","            x_dim = int(x_dim)\n","            x_tensor = tf.reshape(self.x, [-1, x_dim, x_dim, 1])\n","        elif len(self.x.get_shape()) == 4:\n","            x_tensor = self.x\n","        else:\n","            raise ValueError('Unsupported input dimensions')\n","        image = x_tensor\n","    \n","        self.y = tf.placeholder(tf.float32, shape=[None, n_out])\n","        self.LaplaceNoise = tf.placeholder(tf.float32, 25);\n","        self.Delta = tf.placeholder(tf.float32, 1);\n","        ######\n","        \n","        #############################\n","        ##Construct the Model########\n","        #############################\n","        # Create the 1st convolutional restricted boltzmann layer\n","        Enc_Layer1 = EncLayer(inpt=image, n_filter_in = 1, n_filter_out = hidden_layers_sizes[0], filter_size = 5, activation=tf.nn.sigmoid)\n","        self.layers.append(Enc_Layer1)\n","        self.params.extend(Enc_Layer1.params)\n","        # get the pretrain objective function\n","        self.pretrain_ops.append(Enc_Layer1.get_train_ops2(xShape = tf.shape(image)[0], Delta = self.Delta, epsilon = self.epsilon, batch_size = self.batch_size, learning_rate= 0.01))\n","        ###\n","        \n","        # Create the 2nd convolutional restricted boltzmann layer\n","        Enc_Layer2 = EncLayer(inpt=self.layers[-1].output, n_filter_in = hidden_layers_sizes[0], n_filter_out = hidden_layers_sizes[1], filter_size = 5, activation=tf.nn.sigmoid)\n","        self.layers.append(Enc_Layer2)\n","        self.params.extend(Enc_Layer2.params)\n","        # get the pretrain objective function\n","        self.pretrain_ops.append(Enc_Layer2.get_train_ops2(xShape = tf.shape(image)[0], Delta = self.Delta, epsilon = self.epsilon, batch_size = self.batch_size, learning_rate= 0.01))\n","        ###\n","        \n","        # Create the flat connected hidden layer\n","        flat1 = ConvFlat(inpt=self.layers[-1].output, xShape = tf.shape(image)[0], n_out = self.last_n_in, activation=tf.nn.relu)\n","        self.layers.append(flat1)\n","        self.params.extend(flat1.params)\n","        ###\n","        \n","        # Create the output layer\n","        # We use the differentially private Logistic Regression (dpLogisticRegression) layer as the objective function\n","        self.output_layer = dpLogisticRegression(inpt=self.layers[-1].output, n_in = self.last_n_in, n_out=n_out, LaplaceNoise = self.LaplaceNoise)\n","        # We can also use the non-differentially private layer: LogisticRegression(inpt=self.layers[-1].output, n_in=hidden_layers_sizes[-1], n_out=n_out)\n","        self.params.extend(self.output_layer.params)\n","        ###\n","\n","        #######################################\n","        ##Define Fine Tune Cost and Optimizer##\n","        #######################################\n","        # The finetuning cost\n","        self.cost = self.output_layer.cost(self.y)\n","        # train_op for finetuning with AdamOptimizer\n","        global_step = tf.Variable(0, trainable=False)\n","        #learning_rate = tf.train.exponential_decay(finetuneLR, global_step, 700, 0.96, staircase=True); # learning rate decay can be carefully used\n","        # Fine tune with AdamOptimizer. Note that we do not fine tune the pre-trained parameters at the convolutional layers\n","        self.train_op = tf.train.AdamOptimizer(finetuneLR).minimize(self.cost, var_list=[flat1.params, self.output_layer.params], global_step = global_step)\n","        # The accuracy\n","        self.accuracy = self.output_layer.accuarcy(self.y)\n","        ###\n","        \n","    def getDelta(self, v, W, b):\n","        # Set _W and _b to be 1 with the shape of W and b\n","        _W = tf.constant(1.0, shape=W.get_shape())\n","        _b = tf.constant(1.0, shape=b.get_shape())\n","        ###\n","        # Compute hidden neurons in the convolutional layer\n","        h = tf.add(tf.nn.conv2d(v, _W, strides=[1, 2, 2, 1], padding='SAME'), _b)\n","        # Get the max value of hidden neurons\n","        max = tf.reduce_max(h)\n","        # Normalization so that h will satisfy the Riemann integrable condition on [−1, 1]\n","        h = h/max;\n","        # Approxiate hidden neurons by using Chebyshev Polinomial Approximations\n","        Chebyshev_h = tf.clip_by_value(EncLayer.Chebyshev(self = self, x = h), 0.0, 1.0)\n","        # Compute the global sensitivity Delta\n","        Delta = 2.0*tf.reduce_max(tf.abs(tf.reduce_sum(Chebyshev_h, axis=[1, 2])))\n","        # Compute max(v_terms)\n","        v_shape = v.get_shape().as_list()\n","        if (len(v_shape) > 2):\n","            Delta += 2.0*tf.reduce_max(tf.abs(tf.reduce_sum(v, axis=[1, 2])))\n","        else:\n","            Delta += 2.0*tf.reduce_max(tf.abs(tf.reduce_sum(v, axis=[1])))\n","        return Delta\n","    \n","    def generateNoise(n_in, epsilon, batch_size, test = False):\n","        Delta = 0.0;\n","        if test == True: # do not inject noise in the test phase\n","            Delta = 0.0;\n","        else:\n","            Delta = 10*(n_in + 1/4 * n_in**2); # global sensitivity for the output layer, note that 10 is the number of classes of the output layer\n","        # Generate the Laplace noise\n","        perturbFM = np.random.laplace(0.0, Delta/(epsilon*batch_size), n_in)\n","        perturbFM = np.reshape(perturbFM, [n_in]);\n","        return perturbFM;\n","\n","    def pretrain(self, sess, X_train, batch_size=3600, pretraining_epochs=3, lr=0.1, k=1,\n","                    display_step=1):\n","        '''\n","        Pretrain the layers (just train the Convolutional RBM layers)\n","        :param sess: tf.Session\n","        :param X_train: the input of the train set (You might modify this function if you do not use the designed mnist)\n","        :param batch_size: int\n","        :param lr: float\n","        :param k: int, use CD-k\n","        :param pretraining_epoch: int\n","        :param display_step: int\n","        '''\n","        print('Starting pretraining...\\n')\n","        start_time = timeit.default_timer()\n","        batch_num = int(math.ceil(X_train.train.num_examples / batch_size)) # The number of batch per epoch\n","        # Pretrain layer by layer\n","        for i in range(self.n_layers-1):\n","            # Get the cost of the current Convolutional RBM layer\n","            cost = self.layers[i].cost;\n","            # Get the objective function of the current Convolutional RBM layer\n","            train_ops = self.pretrain_ops[i]\n","            # Get the Delta operation of the current Convolutional RBM layer\n","            delta = self.getDelta(v = self.layers[i].input, W = self.layers[i].W, b = self.layers[i].b)\n","            for epoch in range(pretraining_epochs):\n","                avg_cost = 0.0\n","                for j in range(batch_num):\n","                    x_batch, _ = X_train.train.next_batch(batch_size)\n","                    # Compute the actual Delta with the current parameters of the current Convolutional RBM layer\n","                    _Delta = delta.eval(session=sess, feed_dict={self.x: x_batch});\n","                    #print(np.reshape(_Delta, [1]))\n","                    # training\n","                    sess.run(train_ops, feed_dict={self.x: x_batch, self.Delta: np.reshape(_Delta, [1])})\n","                    # cost\n","                    avg_cost += sess.run(cost, feed_dict={self.x: x_batch, self.Delta: np.reshape(_Delta, [1])}) / batch_num\n","                # print out the average cost every display_step\n","                if epoch % display_step == 0:\n","                    print(\"\\tPretraing layer {0} Epoch {1} cost: {2}\".format(i, epoch, avg_cost))\n","\n","        end_time = timeit.default_timer()\n","        print(\"\\nThe pretraining process ran for {0} minutes\".format((end_time - start_time) / 60))\n","    \n","    def finetuning(self, sess, trainSet, training_epochs=200, _epsilon = 0.25, _batch_size = 3600, display_step=10):\n","        '''\n","        Finetuing the network\n","        '''\n","        print(\"\\nStart finetuning...\\n\")\n","        start_time = timeit.default_timer()\n","        \n","        for epoch in range(training_epochs):\n","            #avg_cost = 0.0\n","            batch_num = int(math.ceil(trainSet.train.num_examples / _batch_size)) # The number of batch per epoch\n","            for i in range(batch_num):\n","                x_batch, y_batch = trainSet.train.next_batch(_batch_size)\n","                # training\n","                LapNoise = pCDBN.generateNoise(n_in = 25, epsilon = _epsilon, batch_size = _batch_size, test = False); #Add Laplace noise in training\n","                sess.run(self.train_op, feed_dict={self.x: x_batch, self.y: y_batch, self.LaplaceNoise: LapNoise})\n","            # print out the average cost\n","            if epoch % display_step == 0:\n","                LapNoise = pCDBN.generateNoise(n_in = 25, epsilon = _epsilon, batch_size = _batch_size, test = True); #Do not add noise when testing\n","                val_acc = sess.run(self.accuracy, feed_dict={self.x: trainSet.validation.images,\n","                                                       self.y: trainSet.validation.labels, self.LaplaceNoise: LapNoise})\n","                print(\"\\tEpoch {0} \\t validation accuacy: \\t {1}\".format(epoch, val_acc))\n","                x_a.append(epoch)\n","                y_a.append(val_acc)\n","                #plt.plot(epoch, val_acc, 'ro')\n","                #print(val_acc)\n","                #ax.plot(epoch, val_acc)\n","        end_time = timeit.default_timer()\n","        print(\"\\nThe finetuning process ran for {0} minutes\".format((end_time - start_time) / 60))\n","        plt.plot(x_a,y_a)\n","        plt.title(\"Epochs vs Val_accuracy\")\n","        plt.xlabel(\"Training epochs\")\n","        plt.ylabel(\"Val_accuracy\")\n","      "]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":3205108,"status":"ok","timestamp":1639722144198,"user":{"displayName":"Sri Lalitha","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gisb-ak46FNIdm645NllKqiVAF9jpxvEIpX0fyu0Q=s64","userId":"01193405302123610620"},"user_tz":-330},"id":"QXauXZtICcQe","outputId":"40a96651-b64b-4809-d3b5-e4ef6da090b8"},"outputs":[{"output_type":"stream","name":"stdout","text":["Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n","Extracting MNIST_data/train-images-idx3-ubyte.gz\n","Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n","Extracting MNIST_data/train-labels-idx1-ubyte.gz\n","Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n","Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n","Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n","Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n","Starting pretraining...\n","\n","\tPretraing layer 0 Epoch 0 cost: 0.19998085778206587\n","\tPretraing layer 0 Epoch 1 cost: 0.17625578958541155\n","\tPretraing layer 0 Epoch 2 cost: 0.1595443757250905\n","\tPretraing layer 1 Epoch 0 cost: 0.4363297950476408\n","\tPretraing layer 1 Epoch 1 cost: 0.265798956155777\n","\tPretraing layer 1 Epoch 2 cost: 0.1740975696593523\n","\n","The pretraining process ran for 26.65964349615 minutes\n","\n","Start finetuning...\n","\n","\tEpoch 0 \t validation accuacy: \t 0.2078000009059906\n","\tEpoch 10 \t validation accuacy: \t 0.7483999729156494\n","\tEpoch 20 \t validation accuacy: \t 0.8009999990463257\n","\tEpoch 30 \t validation accuacy: \t 0.8208000063896179\n","\tEpoch 40 \t validation accuacy: \t 0.8285999894142151\n","\tEpoch 50 \t validation accuacy: \t 0.8367999792098999\n","\tEpoch 60 \t validation accuacy: \t 0.8366000056266785\n","\tEpoch 70 \t validation accuacy: \t 0.840399980545044\n","\tEpoch 80 \t validation accuacy: \t 0.8410000205039978\n","\tEpoch 90 \t validation accuacy: \t 0.8410000205039978\n","\tEpoch 100 \t validation accuacy: \t 0.8411999940872192\n","\tEpoch 110 \t validation accuacy: \t 0.8343999981880188\n","\tEpoch 120 \t validation accuacy: \t 0.8317999839782715\n","\tEpoch 130 \t validation accuacy: \t 0.8277999758720398\n","\tEpoch 140 \t validation accuacy: \t 0.8223999738693237\n","\tEpoch 150 \t validation accuacy: \t 0.8140000104904175\n","\tEpoch 160 \t validation accuacy: \t 0.8095999956130981\n","\tEpoch 170 \t validation accuacy: \t 0.807200014591217\n","\tEpoch 180 \t validation accuacy: \t 0.800000011920929\n","\tEpoch 190 \t validation accuacy: \t 0.795799970626831\n","\n","The finetuning process ran for 26.708853741083328 minutes\n"]},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"}}],"source":["if __name__ == \"__main__\":\n","    # mnist examples\n","    mnist = read_data_sets(\"MNIST_data/\", one_hot=True)\n","    dbn = pCDBN(n_in=784, n_out=10, filter_size = 5, hidden_layers_sizes=[32, 64, 25], epsilon = 0.2, _batch_size = 3600, finetuneLR = 2e-4)\n","    sess = tf.Session()\n","    init = tf.global_variables_initializer()\n","    sess.run(init)\n","    # set random_seed for the reproducibility\n","    tf.set_random_seed(seed=1111)\n","    dbn.pretrain(sess, X_train=mnist)\n","    dbn.finetuning(sess, _epsilon = dbn.epsilon, _batch_size = dbn.batch_size, trainSet=mnist)"]},{"cell_type":"markdown","metadata":{"id":"euLVSu0ZACGK"},"source":["epochs vs accuracy (test)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ty0MmXou8das"},"outputs":[],"source":[""]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":1233,"status":"ok","timestamp":1639722774535,"user":{"displayName":"Sri Lalitha","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gisb-ak46FNIdm645NllKqiVAF9jpxvEIpX0fyu0Q=s64","userId":"01193405302123610620"},"user_tz":-330},"id":"o5ixe7BiAdO5"},"outputs":[],"source":["os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n","os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n","x_a=[]\n","y_a=[]\n","class pCDBN(object):\n","    '''\n","    An implement of differentially private convolutional deep belief network\n","    '''\n","    def __init__(self, n_in=784, n_out=10, filter_size = 5, hidden_layers_sizes=[10, 10, 25], epsilon = 0.25, _batch_size = 3600, finetuneLR = 0.01):\n","        '''\n","        :param n_in: int, the dimension of input\n","        :param n_out: int, the dimension of output\n","        :param filter_size: the dimension of convolutional filter [filter_size, filter_size]\n","        :param hidden_layers_sizes: list or tuple, the number of convolutional feature maps, the last item will be the number of hidden neurons in the last hidden layer\n","        :param epsilon: privacy budget epsilon\n","        :param _batch_size: the batch size\n","        :param finetuneLR: fine tunning learning rate\n","        '''\n","        # Number of layers\n","        assert len(hidden_layers_sizes) > 0\n","        self.n_layers = len(hidden_layers_sizes)\n","        self.layers = []    # convolutional and hidden layers\n","        self.params = []       # keep track of params for training\n","        self.last_n_in = hidden_layers_sizes[-1] # the number of hidden neurons in the last hidden layer\n","        self.pretrain_ops = []; # list of pretrain objective functions for convolutional layers\n","        self.epsilon = epsilon; # privacy budget epsilon epsilon\n","        self.batch_size = _batch_size; # batch size\n","\n","        # Define the input, output, Laplace noise for the output layer, and Delta for the pretrain convolutional layers\n","        self.x = tf.placeholder(tf.float32, shape=[None, n_in], name='x')\n","        # ensure 2-d is converted to square tensor.\n","        if len(self.x.get_shape()) == 2:\n","            x_dim = np.sqrt(self.x.get_shape().as_list()[1])\n","            if x_dim != int(x_dim):\n","                raise ValueError('Unsupported input dimensions')\n","            x_dim = int(x_dim)\n","            x_tensor = tf.reshape(self.x, [-1, x_dim, x_dim, 1])\n","        elif len(self.x.get_shape()) == 4:\n","            x_tensor = self.x\n","        else:\n","            raise ValueError('Unsupported input dimensions')\n","        image = x_tensor\n","    \n","        self.y = tf.placeholder(tf.float32, shape=[None, n_out])\n","        self.LaplaceNoise = tf.placeholder(tf.float32, 25);\n","        self.Delta = tf.placeholder(tf.float32, 1);\n","        ######\n","        \n","        #############################\n","        ##Construct the Model########\n","        #############################\n","        # Create the 1st convolutional restricted boltzmann layer\n","        Enc_Layer1 = EncLayer(inpt=image, n_filter_in = 1, n_filter_out = hidden_layers_sizes[0], filter_size = 5, activation=tf.nn.sigmoid)\n","        self.layers.append(Enc_Layer1)\n","        self.params.extend(Enc_Layer1.params)\n","        # get the pretrain objective function\n","        self.pretrain_ops.append(Enc_Layer1.get_train_ops2(xShape = tf.shape(image)[0], Delta = self.Delta, epsilon = self.epsilon, batch_size = self.batch_size, learning_rate= 0.01))\n","        ###\n","        \n","        # Create the 2nd convolutional restricted boltzmann layer\n","        Enc_Layer2 = EncLayer(inpt=self.layers[-1].output, n_filter_in = hidden_layers_sizes[0], n_filter_out = hidden_layers_sizes[1], filter_size = 5, activation=tf.nn.sigmoid)\n","        self.layers.append(Enc_Layer2)\n","        self.params.extend(Enc_Layer2.params)\n","        # get the pretrain objective function\n","        self.pretrain_ops.append(Enc_Layer2.get_train_ops2(xShape = tf.shape(image)[0], Delta = self.Delta, epsilon = self.epsilon, batch_size = self.batch_size, learning_rate= 0.01))\n","        ###\n","        \n","        # Create the flat connected hidden layer\n","        flat1 = ConvFlat(inpt=self.layers[-1].output, xShape = tf.shape(image)[0], n_out = self.last_n_in, activation=tf.nn.relu)\n","        self.layers.append(flat1)\n","        self.params.extend(flat1.params)\n","        ###\n","        \n","        # Create the output layer\n","        # We use the differentially private Logistic Regression (dpLogisticRegression) layer as the objective function\n","        self.output_layer = dpLogisticRegression(inpt=self.layers[-1].output, n_in = self.last_n_in, n_out=n_out, LaplaceNoise = self.LaplaceNoise)\n","        # We can also use the non-differentially private layer: LogisticRegression(inpt=self.layers[-1].output, n_in=hidden_layers_sizes[-1], n_out=n_out)\n","        self.params.extend(self.output_layer.params)\n","        ###\n","\n","        #######################################\n","        ##Define Fine Tune Cost and Optimizer##\n","        #######################################\n","        # The finetuning cost\n","        self.cost = self.output_layer.cost(self.y)\n","        # train_op for finetuning with AdamOptimizer\n","        global_step = tf.Variable(0, trainable=False)\n","        #learning_rate = tf.train.exponential_decay(finetuneLR, global_step, 700, 0.96, staircase=True); # learning rate decay can be carefully used\n","        # Fine tune with AdamOptimizer. Note that we do not fine tune the pre-trained parameters at the convolutional layers\n","        self.train_op = tf.train.AdamOptimizer(finetuneLR).minimize(self.cost, var_list=[flat1.params, self.output_layer.params], global_step = global_step)\n","        # The accuracy\n","        self.accuracy = self.output_layer.accuarcy(self.y)\n","        ###\n","        \n","    def getDelta(self, v, W, b):\n","        # Set _W and _b to be 1 with the shape of W and b\n","        _W = tf.constant(1.0, shape=W.get_shape())\n","        _b = tf.constant(1.0, shape=b.get_shape())\n","        ###\n","        # Compute hidden neurons in the convolutional layer\n","        h = tf.add(tf.nn.conv2d(v, _W, strides=[1, 2, 2, 1], padding='SAME'), _b)\n","        # Get the max value of hidden neurons\n","        max = tf.reduce_max(h)\n","        # Normalization so that h will satisfy the Riemann integrable condition on [−1, 1]\n","        h = h/max;\n","        # Approxiate hidden neurons by using Chebyshev Polinomial Approximations\n","        Chebyshev_h = tf.clip_by_value(EncLayer.Chebyshev(self = self, x = h), 0.0, 1.0)\n","        # Compute the global sensitivity Delta\n","        Delta = 2.0*tf.reduce_max(tf.abs(tf.reduce_sum(Chebyshev_h, axis=[1, 2])))\n","        # Compute max(v_terms)\n","        v_shape = v.get_shape().as_list()\n","        if (len(v_shape) > 2):\n","            Delta += 2.0*tf.reduce_max(tf.abs(tf.reduce_sum(v, axis=[1, 2])))\n","        else:\n","            Delta += 2.0*tf.reduce_max(tf.abs(tf.reduce_sum(v, axis=[1])))\n","        return Delta\n","    \n","    def generateNoise(n_in, epsilon, batch_size, test = False):\n","        Delta = 0.0;\n","        if test == True: # do not inject noise in the test phase\n","            Delta = 0.0;\n","        else:\n","            Delta = 10*(n_in + 1/4 * n_in**2); # global sensitivity for the output layer, note that 10 is the number of classes of the output layer\n","        # Generate the Laplace noise\n","        perturbFM = np.random.laplace(0.0, Delta/(epsilon*batch_size), n_in)\n","        perturbFM = np.reshape(perturbFM, [n_in]);\n","        return perturbFM;\n","\n","    def pretrain(self, sess, X_train, batch_size=3600, pretraining_epochs=3, lr=0.1, k=1,\n","                    display_step=1):\n","        '''\n","        Pretrain the layers (just train the Convolutional RBM layers)\n","        :param sess: tf.Session\n","        :param X_train: the input of the train set (You might modify this function if you do not use the designed mnist)\n","        :param batch_size: int\n","        :param lr: float\n","        :param k: int, use CD-k\n","        :param pretraining_epoch: int\n","        :param display_step: int\n","        '''\n","        print('Starting pretraining...\\n')\n","        start_time = timeit.default_timer()\n","        batch_num = int(math.ceil(X_train.test.num_examples / batch_size)) # The number of batch per epoch  -----------------------\n","        # Pretrain layer by layer\n","        for i in range(self.n_layers-1):\n","            # Get the cost of the current Convolutional RBM layer\n","            cost = self.layers[i].cost;\n","            # Get the objective function of the current Convolutional RBM layer\n","            train_ops = self.pretrain_ops[i]\n","            # Get the Delta operation of the current Convolutional RBM layer\n","            delta = self.getDelta(v = self.layers[i].input, W = self.layers[i].W, b = self.layers[i].b)\n","            for epoch in range(pretraining_epochs):\n","                avg_cost = 0.0\n","                for j in range(batch_num):\n","                    x_batch, _ = X_train.test.next_batch(batch_size)  #------------------------------\n","                    # Compute the actual Delta with the current parameters of the current Convolutional RBM layer\n","                    _Delta = delta.eval(session=sess, feed_dict={self.x: x_batch});\n","                    #print(np.reshape(_Delta, [1]))\n","                    # training\n","                    sess.run(train_ops, feed_dict={self.x: x_batch, self.Delta: np.reshape(_Delta, [1])})\n","                    # cost\n","                    avg_cost += sess.run(cost, feed_dict={self.x: x_batch, self.Delta: np.reshape(_Delta, [1])}) / batch_num\n","                # print out the average cost every display_step\n","                if epoch % display_step == 0:\n","                    print(\"\\tPretraing layer {0} Epoch {1} cost: {2}\".format(i, epoch, avg_cost))\n","\n","        end_time = timeit.default_timer()\n","        print(\"\\nThe pretraining process ran for {0} minutes\".format((end_time - start_time) / 60))\n","    \n","    def finetuning(self, sess, trainSet, training_epochs=200, _epsilon = 0.25, _batch_size = 3600, display_step=10):\n","        '''\n","        Finetuing the network\n","        '''\n","        print(\"\\nStart finetuning...\\n\")\n","        start_time = timeit.default_timer()\n","        \n","        for epoch in range(training_epochs):\n","            #avg_cost = 0.0\n","            batch_num = int(math.ceil(trainSet.test.num_examples / _batch_size)) # The number of batch per epoch  ----------------------------\n","            for i in range(batch_num):\n","                x_batch, y_batch = trainSet.test.next_batch(_batch_size)  #----------------------\n","                # training\n","                LapNoise = pCDBN.generateNoise(n_in = 25, epsilon = _epsilon, batch_size = _batch_size, test = False); #Add Laplace noise in training\n","                sess.run(self.train_op, feed_dict={self.x: x_batch, self.y: y_batch, self.LaplaceNoise: LapNoise})\n","            # print out the average cost\n","            if epoch % display_step == 0:\n","                LapNoise = pCDBN.generateNoise(n_in = 25, epsilon = _epsilon, batch_size = _batch_size, test = True); #Do not add noise when testing\n","                val_acc = sess.run(self.accuracy, feed_dict={self.x: trainSet.validation.images, self.y: trainSet.validation.labels, self.LaplaceNoise: LapNoise}) #--------\n","                print(\"\\tEpoch {0} \\t validation accuacy: \\t {1}\".format(epoch, val_acc))\n","                x_a.append(epoch)\n","                y_a.append(val_acc)\n","                #plt.plot(epoch, val_acc, 'ro')\n","                #print(val_acc)\n","                #ax.plot(epoch, val_acc)\n","        end_time = timeit.default_timer()\n","        print(\"\\nThe finetuning process ran for {0} minutes\".format((end_time - start_time) / 60))\n","        plt.plot(x_a,y_a)\n","        plt.title(\"Epochs vs Val_accuracy\")\n","        plt.xlabel(\"Training epochs\")\n","        plt.ylabel(\"Val_accuracy\")"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":619561,"status":"ok","timestamp":1639723396674,"user":{"displayName":"Sri Lalitha","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gisb-ak46FNIdm645NllKqiVAF9jpxvEIpX0fyu0Q=s64","userId":"01193405302123610620"},"user_tz":-330},"id":"ajKodfdBDYkb","outputId":"5397fa73-a8e5-4a0f-8534-f881c7a8fb62"},"outputs":[{"output_type":"stream","name":"stdout","text":["Extracting MNIST_data/train-images-idx3-ubyte.gz\n","Extracting MNIST_data/train-labels-idx1-ubyte.gz\n","Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n","Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n","Starting pretraining...\n","\n","\tPretraing layer 0 Epoch 0 cost: 0.22183305521806085\n","\tPretraing layer 0 Epoch 1 cost: 0.2152162492275238\n","\tPretraing layer 0 Epoch 2 cost: 0.20251747965812683\n","\tPretraing layer 1 Epoch 0 cost: 0.5647542079289755\n","\tPretraing layer 1 Epoch 1 cost: 0.48142596085866296\n","\tPretraing layer 1 Epoch 2 cost: 0.4289736052354177\n","\n","The pretraining process ran for 5.051508249350006 minutes\n","\n","Start finetuning...\n","\n","\tEpoch 0 \t validation accuacy: \t 0.10040000081062317\n","\tEpoch 10 \t validation accuacy: \t 0.24500000476837158\n","\tEpoch 20 \t validation accuacy: \t 0.391400009393692\n","\tEpoch 30 \t validation accuacy: \t 0.4821999967098236\n","\tEpoch 40 \t validation accuacy: \t 0.5428000092506409\n","\tEpoch 50 \t validation accuacy: \t 0.5953999757766724\n","\tEpoch 60 \t validation accuacy: \t 0.6230000257492065\n","\tEpoch 70 \t validation accuacy: \t 0.63919997215271\n","\tEpoch 80 \t validation accuacy: \t 0.6488000154495239\n","\tEpoch 90 \t validation accuacy: \t 0.6682000160217285\n","\tEpoch 100 \t validation accuacy: \t 0.6751999855041504\n","\tEpoch 110 \t validation accuacy: \t 0.6941999793052673\n","\tEpoch 120 \t validation accuacy: \t 0.7017999887466431\n","\tEpoch 130 \t validation accuacy: \t 0.7095999717712402\n","\tEpoch 140 \t validation accuacy: \t 0.7134000062942505\n","\tEpoch 150 \t validation accuacy: \t 0.7179999947547913\n","\tEpoch 160 \t validation accuacy: \t 0.7247999906539917\n","\tEpoch 170 \t validation accuacy: \t 0.725600004196167\n","\tEpoch 180 \t validation accuacy: \t 0.7264000177383423\n","\tEpoch 190 \t validation accuacy: \t 0.7261999845504761\n","\n","The finetuning process ran for 5.229040165833324 minutes\n"]},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"}}],"source":["if __name__ == \"__main__\":\n","    # mnist examples\n","    mnist = read_data_sets(\"MNIST_data/\", one_hot=True)\n","    dbn = pCDBN(n_in=784, n_out=10, filter_size = 5, hidden_layers_sizes=[32, 64, 25], epsilon = 0.2, _batch_size = 3600, finetuneLR = 2e-4)\n","    sess = tf.Session()\n","    init = tf.global_variables_initializer()\n","    sess.run(init)\n","    # set random_seed for the reproducibility\n","    tf.set_random_seed(seed=1111)\n","    dbn.pretrain(sess, X_train=mnist)\n","    dbn.finetuning(sess, _epsilon = dbn.epsilon, _batch_size = dbn.batch_size, trainSet=mnist)\n","    "]},{"cell_type":"markdown","metadata":{"id":"79YNhT9E_wE8"},"source":["epsilon vs accuracy"]},{"cell_type":"code","execution_count":14,"metadata":{"executionInfo":{"elapsed":1240,"status":"ok","timestamp":1639724560415,"user":{"displayName":"Sri Lalitha","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gisb-ak46FNIdm645NllKqiVAF9jpxvEIpX0fyu0Q=s64","userId":"01193405302123610620"},"user_tz":-330},"id":"X2Q357TF-EHG"},"outputs":[],"source":["os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n","os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n","x_a=[]\n","y_a=[]\n","class pCDBN(object):\n","    '''\n","    An implement of differentially private convolutional deep belief network\n","    '''\n","    def __init__(self, n_in=784, n_out=10, filter_size = 5, hidden_layers_sizes=[10, 10, 25], epsilon = 0.25, _batch_size = 3600, finetuneLR = 0.01):\n","        '''\n","        :param n_in: int, the dimension of input\n","        :param n_out: int, the dimension of output\n","        :param filter_size: the dimension of convolutional filter [filter_size, filter_size]\n","        :param hidden_layers_sizes: list or tuple, the number of convolutional feature maps, the last item will be the number of hidden neurons in the last hidden layer\n","        :param epsilon: privacy budget epsilon\n","        :param _batch_size: the batch size\n","        :param finetuneLR: fine tunning learning rate\n","        '''\n","        # Number of layers\n","        assert len(hidden_layers_sizes) > 0\n","        self.n_layers = len(hidden_layers_sizes)\n","        self.layers = []    # convolutional and hidden layers\n","        self.params = []       # keep track of params for training\n","        self.last_n_in = hidden_layers_sizes[-1] # the number of hidden neurons in the last hidden layer\n","        self.pretrain_ops = []; # list of pretrain objective functions for convolutional layers\n","        self.epsilon = epsilon; # privacy budget epsilon epsilon\n","        self.batch_size = _batch_size; # batch size\n","\n","        # Define the input, output, Laplace noise for the output layer, and Delta for the pretrain convolutional layers\n","        self.x = tf.placeholder(tf.float32, shape=[None, n_in], name='x')\n","        # ensure 2-d is converted to square tensor.\n","        if len(self.x.get_shape()) == 2:\n","            x_dim = np.sqrt(self.x.get_shape().as_list()[1])\n","            if x_dim != int(x_dim):\n","                raise ValueError('Unsupported input dimensions')\n","            x_dim = int(x_dim)\n","            x_tensor = tf.reshape(self.x, [-1, x_dim, x_dim, 1])\n","        elif len(self.x.get_shape()) == 4:\n","            x_tensor = self.x\n","        else:\n","            raise ValueError('Unsupported input dimensions')\n","        image = x_tensor\n","    \n","        self.y = tf.placeholder(tf.float32, shape=[None, n_out])\n","        self.LaplaceNoise = tf.placeholder(tf.float32, 25);\n","        self.Delta = tf.placeholder(tf.float32, 1);\n","        ######\n","        \n","        #############################\n","        ##Construct the Model########\n","        #############################\n","        # Create the 1st convolutional restricted boltzmann layer\n","        Enc_Layer1 = EncLayer(inpt=image, n_filter_in = 1, n_filter_out = hidden_layers_sizes[0], filter_size = 5, activation=tf.nn.sigmoid)\n","        self.layers.append(Enc_Layer1)\n","        self.params.extend(Enc_Layer1.params)\n","        # get the pretrain objective function\n","        self.pretrain_ops.append(Enc_Layer1.get_train_ops2(xShape = tf.shape(image)[0], Delta = self.Delta, epsilon = self.epsilon, batch_size = self.batch_size, learning_rate= 0.01))\n","        ###\n","        \n","        # Create the 2nd convolutional restricted boltzmann layer\n","        Enc_Layer2 = EncLayer(inpt=self.layers[-1].output, n_filter_in = hidden_layers_sizes[0], n_filter_out = hidden_layers_sizes[1], filter_size = 5, activation=tf.nn.sigmoid)\n","        self.layers.append(Enc_Layer2)\n","        self.params.extend(Enc_Layer2.params)\n","        # get the pretrain objective function\n","        self.pretrain_ops.append(Enc_Layer2.get_train_ops2(xShape = tf.shape(image)[0], Delta = self.Delta, epsilon = self.epsilon, batch_size = self.batch_size, learning_rate= 0.01))\n","        ###\n","        \n","        # Create the flat connected hidden layer\n","        flat1 = ConvFlat(inpt=self.layers[-1].output, xShape = tf.shape(image)[0], n_out = self.last_n_in, activation=tf.nn.relu)\n","        self.layers.append(flat1)\n","        self.params.extend(flat1.params)\n","        ###\n","        \n","        # Create the output layer\n","        # We use the differentially private Logistic Regression (dpLogisticRegression) layer as the objective function\n","        self.output_layer = dpLogisticRegression(inpt=self.layers[-1].output, n_in = self.last_n_in, n_out=n_out, LaplaceNoise = self.LaplaceNoise)\n","        # We can also use the non-differentially private layer: LogisticRegression(inpt=self.layers[-1].output, n_in=hidden_layers_sizes[-1], n_out=n_out)\n","        self.params.extend(self.output_layer.params)\n","        ###\n","\n","        #######################################\n","        ##Define Fine Tune Cost and Optimizer##\n","        #######################################\n","        # The finetuning cost\n","        self.cost = self.output_layer.cost(self.y)\n","        # train_op for finetuning with AdamOptimizer\n","        global_step = tf.Variable(0, trainable=False)\n","        #learning_rate = tf.train.exponential_decay(finetuneLR, global_step, 700, 0.96, staircase=True); # learning rate decay can be carefully used\n","        # Fine tune with AdamOptimizer. Note that we do not fine tune the pre-trained parameters at the convolutional layers\n","        self.train_op = tf.train.AdamOptimizer(finetuneLR).minimize(self.cost, var_list=[flat1.params, self.output_layer.params], global_step = global_step)\n","        # The accuracy\n","        self.accuracy = self.output_layer.accuarcy(self.y)\n","        ###\n","        \n","    def getDelta(self, v, W, b):\n","        # Set _W and _b to be 1 with the shape of W and b\n","        _W = tf.constant(1.0, shape=W.get_shape())\n","        _b = tf.constant(1.0, shape=b.get_shape())\n","        ###\n","        # Compute hidden neurons in the convolutional layer\n","        h = tf.add(tf.nn.conv2d(v, _W, strides=[1, 2, 2, 1], padding='SAME'), _b)\n","        # Get the max value of hidden neurons\n","        max = tf.reduce_max(h)\n","        # Normalization so that h will satisfy the Riemann integrable condition on [−1, 1]\n","        h = h/max;\n","        # Approxiate hidden neurons by using Chebyshev Polinomial Approximations\n","        Chebyshev_h = tf.clip_by_value(EncLayer.Chebyshev(self = self, x = h), 0.0, 1.0)\n","        # Compute the global sensitivity Delta\n","        Delta = 2.0*tf.reduce_max(tf.abs(tf.reduce_sum(Chebyshev_h, axis=[1, 2])))\n","        # Compute max(v_terms)\n","        v_shape = v.get_shape().as_list()\n","        if (len(v_shape) > 2):\n","            Delta += 2.0*tf.reduce_max(tf.abs(tf.reduce_sum(v, axis=[1, 2])))\n","        else:\n","            Delta += 2.0*tf.reduce_max(tf.abs(tf.reduce_sum(v, axis=[1])))\n","        return Delta\n","    \n","    def generateNoise(n_in, epsilon, batch_size, test = False):\n","        Delta = 0.0;\n","        if test == True: # do not inject noise in the test phase\n","            Delta = 0.0;\n","        else:\n","            Delta = 10*(n_in + 1/4 * n_in**2); # global sensitivity for the output layer, note that 10 is the number of classes of the output layer\n","        # Generate the Laplace noise\n","        perturbFM = np.random.laplace(0.0, Delta/(epsilon*batch_size), n_in)\n","        perturbFM = np.reshape(perturbFM, [n_in]);\n","        return perturbFM;\n","\n","    def pretrain(self, sess, X_train, batch_size=3600, pretraining_epochs=3, lr=0.1, k=1,\n","                    display_step=1):\n","        '''\n","        Pretrain the layers (just train the Convolutional RBM layers)\n","        :param sess: tf.Session\n","        :param X_train: the input of the train set (You might modify this function if you do not use the designed mnist)\n","        :param batch_size: int\n","        :param lr: float\n","        :param k: int, use CD-k\n","        :param pretraining_epoch: int\n","        :param display_step: int\n","        '''\n","        print('Starting pretraining...\\n')\n","        start_time = timeit.default_timer()\n","        batch_num = int(math.ceil(X_train.test.num_examples / batch_size)) # The number of batch per epoch  -----------------------\n","        # Pretrain layer by layer\n","        for i in range(self.n_layers-1):\n","            # Get the cost of the current Convolutional RBM layer\n","            cost = self.layers[i].cost;\n","            # Get the objective function of the current Convolutional RBM layer\n","            train_ops = self.pretrain_ops[i]\n","            # Get the Delta operation of the current Convolutional RBM layer\n","            delta = self.getDelta(v = self.layers[i].input, W = self.layers[i].W, b = self.layers[i].b)\n","            for epoch in range(pretraining_epochs):\n","                avg_cost = 0.0\n","                for j in range(batch_num):\n","                    x_batch, _ = X_train.test.next_batch(batch_size)  #------------------------------\n","                    # Compute the actual Delta with the current parameters of the current Convolutional RBM layer\n","                    _Delta = delta.eval(session=sess, feed_dict={self.x: x_batch});\n","                    #print(np.reshape(_Delta, [1]))\n","                    # training\n","                    sess.run(train_ops, feed_dict={self.x: x_batch, self.Delta: np.reshape(_Delta, [1])})\n","                    # cost\n","                    avg_cost += sess.run(cost, feed_dict={self.x: x_batch, self.Delta: np.reshape(_Delta, [1])}) / batch_num\n","                # print out the average cost every display_step\n","                if epoch % display_step == 0:\n","                    print(\"\\tPretraing layer {0} Epoch {1} cost: {2}\".format(i, epoch, avg_cost))\n","\n","        end_time = timeit.default_timer()\n","        print(\"\\nThe pretraining process ran for {0} minutes\".format((end_time - start_time) / 60))\n","    \n","    def finetuning(self, sess, trainSet, training_epochs=100, _epsilon = 0.25, _batch_size = 3600, display_step=9):\n","        '''\n","        Finetuing the network\n","        '''\n","        print(\"\\nStart finetuning...\\n\")\n","        start_time = timeit.default_timer()\n","        \n","        for epoch in range(training_epochs):\n","            #avg_cost = 0.0\n","            batch_num = int(math.ceil(trainSet.test.num_examples / _batch_size)) # The number of batch per epoch  ----------------------------\n","            for i in range(batch_num):\n","                x_batch, y_batch = trainSet.test.next_batch(_batch_size)  #----------------------\n","                # training\n","                LapNoise = pCDBN.generateNoise(n_in = 25, epsilon = _epsilon, batch_size = _batch_size, test = False); #Add Laplace noise in training\n","                sess.run(self.train_op, feed_dict={self.x: x_batch, self.y: y_batch, self.LaplaceNoise: LapNoise})\n","            # print out the average cost\n","            if epoch % display_step == 0:\n","                LapNoise = pCDBN.generateNoise(n_in = 25, epsilon = _epsilon, batch_size = _batch_size, test = True); #Do not add noise when testing\n","                val_acc = sess.run(self.accuracy, feed_dict={self.x: trainSet.validation.images, self.y: trainSet.validation.labels, self.LaplaceNoise: LapNoise}) #--------\n","                #print(\"\\tEpoch {0} \\t validation accuacy: \\t {1}\".format(epoch, val_acc))\n","                if epoch==99:\n","                  print(\"\\tepsilon {0} \\t validation accuracy: \\t {1}\".format(_epsilon,val_acc))\n","                #x_a.append(epoch)\n","                #y_a.append(val_acc)\n","                  x_a.append(_epsilon)\n","                  y_a.append(val_acc)\n","                #plt.plot(epoch, val_acc, 'ro')\n","                #print(val_acc)\n","                #ax.plot(epoch, val_acc)\n","        end_time = timeit.default_timer()\n","        print(\"\\nThe finetuning process ran for {0} minutes\".format((end_time - start_time) / 60))\n","        #plt.plot(x_a,y_a)\n","        plt.plot(x_a,y_a)\n","        #plt.title(\"Epochs vs Val_accuracy\")\n","        plt.title(\"epsilon vs Val_accuracy\")\n","        #plt.xlabel(\"Training epochs\")\n","        plt.xlabel(\"epsilon\")\n","        #plt.ylabel(\"Val_accuracy\")\n","        plt.ylabel(\"Val_accuracy\")"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"executionInfo":{"elapsed":1837731,"status":"ok","timestamp":1639726725614,"user":{"displayName":"Sri Lalitha","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gisb-ak46FNIdm645NllKqiVAF9jpxvEIpX0fyu0Q=s64","userId":"01193405302123610620"},"user_tz":-330},"id":"vC7ECAIWSH6M","outputId":"434cfac0-b5c5-480e-a975-75c345db4eaa"},"outputs":[{"output_type":"stream","name":"stdout","text":["Extracting MNIST_data/train-images-idx3-ubyte.gz\n","Extracting MNIST_data/train-labels-idx1-ubyte.gz\n","Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n","Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n","Starting pretraining...\n","\n","\tPretraing layer 0 Epoch 0 cost: 0.29218417406082153\n","\tPretraing layer 0 Epoch 1 cost: 0.2809419631958008\n","\tPretraing layer 0 Epoch 2 cost: 0.24173040191332495\n","\tPretraing layer 1 Epoch 0 cost: 0.4463885029157002\n","\tPretraing layer 1 Epoch 1 cost: 0.3581643005212148\n","\tPretraing layer 1 Epoch 2 cost: 0.2535982032616933\n","\n","The pretraining process ran for 5.002673407216662 minutes\n","\n","Start finetuning...\n","\n","\tepsilon 0.1 \t validation accuracy: \t 0.48579999804496765\n","\n","The finetuning process ran for 2.646467130000004 minutes\n","Starting pretraining...\n","\n","\tPretraing layer 0 Epoch 0 cost: 0.1922091394662857\n","\tPretraing layer 0 Epoch 1 cost: 0.18635655442873636\n","\tPretraing layer 0 Epoch 2 cost: 0.18298584719498953\n","\tPretraing layer 1 Epoch 0 cost: 0.5483849843343098\n","\tPretraing layer 1 Epoch 1 cost: 0.4612861375013987\n","\tPretraing layer 1 Epoch 2 cost: 0.44195928176244104\n","\n","The pretraining process ran for 4.9861030801166635 minutes\n","\n","Start finetuning...\n","\n","\tepsilon 0.3 \t validation accuracy: \t 0.6894000172615051\n","\n","The finetuning process ran for 2.637479614033327 minutes\n","Starting pretraining...\n","\n","\tPretraing layer 0 Epoch 0 cost: 0.22471310695012411\n","\tPretraing layer 0 Epoch 1 cost: 0.2169178078571955\n","\tPretraing layer 0 Epoch 2 cost: 0.20988401770591736\n","\tPretraing layer 1 Epoch 0 cost: 0.4410789509614309\n","\tPretraing layer 1 Epoch 1 cost: 0.37020302812258404\n","\tPretraing layer 1 Epoch 2 cost: 0.3217280010382334\n","\n","The pretraining process ran for 4.946302400116656 minutes\n","\n","Start finetuning...\n","\n","\tepsilon 0.5 \t validation accuracy: \t 0.6600000262260437\n","\n","The finetuning process ran for 2.644161272216661 minutes\n","Starting pretraining...\n","\n","\tPretraing layer 0 Epoch 0 cost: 0.19902755320072174\n","\tPretraing layer 0 Epoch 1 cost: 0.2032775580883026\n","\tPretraing layer 0 Epoch 2 cost: 0.1987026035785675\n","\tPretraing layer 1 Epoch 0 cost: 0.5368458131949106\n","\tPretraing layer 1 Epoch 1 cost: 0.43415195743242896\n","\tPretraing layer 1 Epoch 2 cost: 0.37327529986699426\n","\n","The pretraining process ran for 4.9787554569000045 minutes\n","\n","Start finetuning...\n","\n","\tepsilon 0.7 \t validation accuracy: \t 0.5878000259399414\n","\n","The finetuning process ran for 2.6369986146833373 minutes\n"]},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"}}],"source":["if __name__ == \"__main__\":\n","    # mnist examples\n","    mnist = read_data_sets(\"MNIST_data/\", one_hot=True)\n","    itrl =[0.1,0.3,0.5,0.7]\n","    for i in range(len(itrl)):\n","      dbn = pCDBN(n_in=784, n_out=10, filter_size = 5, hidden_layers_sizes=[32, 64, 25], epsilon = itrl[i], _batch_size = 3600, finetuneLR = 2e-4)\n","      sess = tf.Session()\n","      init = tf.global_variables_initializer()\n","      sess.run(init)\n","    # set random_seed for the reproducibility\n","      tf.set_random_seed(seed=1111)\n","      dbn.pretrain(sess, X_train=mnist)\n","      dbn.finetuning(sess, _epsilon = dbn.epsilon, _batch_size = dbn.batch_size, trainSet=mnist)"]},{"cell_type":"markdown","metadata":{"id":"y63IMUWLBTMQ"},"source":["Comparision"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9lpyxotU_tko"},"outputs":[],"source":[""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"C9HWNQWTumlc"},"outputs":[],"source":["os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n","os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n","x_a=[]\n","y_a=[]\n","class pCDBN(object):\n","    '''\n","    An implement of differentially private convolutional deep belief network\n","    '''\n","    def __init__(self, n_in=784, n_out=10, filter_size = 5, hidden_layers_sizes=[10, 10, 25, 25], epsilon = 0.25, _batch_size = 3600, finetuneLR = 0.01):\n","        '''\n","        :param n_in: int, the dimension of input\n","        :param n_out: int, the dimension of output\n","        :param filter_size: the dimension of convolutional filter [filter_size, filter_size]\n","        :param hidden_layers_sizes: list or tuple, the number of convolutional feature maps, the last item will be the number of hidden neurons in the last hidden layer\n","        :param epsilon: privacy budget epsilon\n","        :param _batch_size: the batch size\n","        :param finetuneLR: fine tunning learning rate\n","        '''\n","        # Number of layers\n","        assert len(hidden_layers_sizes) > 0\n","        self.n_layers = len(hidden_layers_sizes)\n","        self.layers = []    # convolutional and hidden layers\n","        self.params = []       # keep track of params for training\n","        self.last_n_in = hidden_layers_sizes[-1] # the number of hidden neurons in the last hidden layer\n","        self.pretrain_ops = []; # list of pretrain objective functions for convolutional layers\n","        self.epsilon = epsilon; # privacy budget epsilon epsilon\n","        self.batch_size = _batch_size; # batch size\n","\n","        # Define the input, output, Laplace noise for the output layer, and Delta for the pretrain convolutional layers\n","        self.x = tf.placeholder(tf.float32, shape=[None, n_in], name='x')\n","        # ensure 2-d is converted to square tensor.\n","        if len(self.x.get_shape()) == 2:\n","            x_dim = np.sqrt(self.x.get_shape().as_list()[1])\n","            if x_dim != int(x_dim):\n","                raise ValueError('Unsupported input dimensions')\n","            x_dim = int(x_dim)\n","            x_tensor = tf.reshape(self.x, [-1, x_dim, x_dim, 1])\n","        elif len(self.x.get_shape()) == 4:\n","            x_tensor = self.x\n","        else:\n","            raise ValueError('Unsupported input dimensions')\n","        image = x_tensor\n","    \n","        self.y = tf.placeholder(tf.float32, shape=[None, n_out])\n","        self.LaplaceNoise = tf.placeholder(tf.float32, 25);\n","        self.Delta = tf.placeholder(tf.float32, 1);\n","        ######\n","        \n","        #############################\n","        ##Construct the Model########\n","        #############################\n","        # Create the 1st convolutional restricted boltzmann layer\n","        Enc_Layer1 = EncLayer(inpt=image, n_filter_in = 1, n_filter_out = hidden_layers_sizes[0], filter_size = 5, activation=tf.nn.sigmoid)\n","        self.layers.append(Enc_Layer1)\n","        self.params.extend(Enc_Layer1.params)\n","        # get the pretrain objective function\n","        self.pretrain_ops.append(Enc_Layer1.get_train_ops2(xShape = tf.shape(image)[0], Delta = self.Delta, epsilon = self.epsilon, batch_size = self.batch_size, learning_rate= 0.01))\n","        ###\n","        \n","        # Create the 2nd convolutional restricted boltzmann layer\n","        Enc_Layer2 = EncLayer(inpt=self.layers[-1].output, n_filter_in = hidden_layers_sizes[0], n_filter_out = hidden_layers_sizes[1], filter_size = 5, activation=tf.nn.sigmoid)\n","        self.layers.append(Enc_Layer2)\n","        self.params.extend(Enc_Layer2.params)\n","        # get the pretrain objective function\n","        self.pretrain_ops.append(Enc_Layer2.get_train_ops2(xShape = tf.shape(image)[0], Delta = self.Delta, epsilon = self.epsilon, batch_size = self.batch_size, learning_rate= 0.01))\n","        ###\n","\n","        Enc_Layer3 = EncLayer(inpt=self.layers[-1].output, n_filter_in = hidden_layers_sizes[1], n_filter_out = hidden_layers_sizes[2], filter_size = 5, activation=tf.nn.sigmoid)\n","        self.layers.append(Enc_Layer3)\n","        self.params.extend(Enc_Layer3.params)\n","        # get the pretrain objective function\n","        self.pretrain_ops.append(Enc_Layer3.get_train_ops2(xShape = tf.shape(image)[0], Delta = self.Delta, epsilon = self.epsilon, batch_size = self.batch_size, learning_rate= 0.01))\n","        ###\n","        \n","        # Create the flat connected hidden layer\n","        flat1 = ConvFlat(inpt=self.layers[-1].output, xShape = tf.shape(image)[0], n_out = self.last_n_in, activation=tf.nn.relu)\n","        self.layers.append(flat1)\n","        self.params.extend(flat1.params)\n","        ###\n","        \n","        # Create the output layer\n","        # We use the differentially private Logistic Regression (dpLogisticRegression) layer as the objective function\n","        self.output_layer = dpLogisticRegression(inpt=self.layers[-1].output, n_in = self.last_n_in, n_out=n_out, LaplaceNoise = self.LaplaceNoise)\n","        # We can also use the non-differentially private layer: LogisticRegression(inpt=self.layers[-1].output, n_in=hidden_layers_sizes[-1], n_out=n_out)\n","        self.params.extend(self.output_layer.params)\n","        ###\n","\n","        #######################################\n","        ##Define Fine Tune Cost and Optimizer##\n","        #######################################\n","        # The finetuning cost\n","        self.cost = self.output_layer.cost(self.y)\n","        # train_op for finetuning with AdamOptimizer\n","        global_step = tf.Variable(0, trainable=False)\n","        #learning_rate = tf.train.exponential_decay(finetuneLR, global_step, 700, 0.96, staircase=True); # learning rate decay can be carefully used\n","        # Fine tune with AdamOptimizer. Note that we do not fine tune the pre-trained parameters at the convolutional layers\n","        self.train_op = tf.train.AdamOptimizer(finetuneLR).minimize(self.cost, var_list=[flat1.params, self.output_layer.params], global_step = global_step)\n","        # The accuracy\n","        self.accuracy = self.output_layer.accuarcy(self.y)\n","        ###\n","        \n","    def getDelta(self, v, W, b):\n","        # Set _W and _b to be 1 with the shape of W and b\n","        _W = tf.constant(1.0, shape=W.get_shape())\n","        _b = tf.constant(1.0, shape=b.get_shape())\n","        ###\n","        # Compute hidden neurons in the convolutional layer\n","        h = tf.add(tf.nn.conv2d(v, _W, strides=[1, 2, 2, 1], padding='SAME'), _b)\n","        # Get the max value of hidden neurons\n","        max = tf.reduce_max(h)\n","        # Normalization so that h will satisfy the Riemann integrable condition on [−1, 1]\n","        h = h/max;\n","        # Approxiate hidden neurons by using Chebyshev Polinomial Approximations\n","        Chebyshev_h = tf.clip_by_value(EncLayer.Chebyshev(self = self, x = h), 0.0, 1.0)\n","        # Compute the global sensitivity Delta\n","        Delta = 2.0*tf.reduce_max(tf.abs(tf.reduce_sum(Chebyshev_h, axis=[1, 2])))\n","        # Compute max(v_terms)\n","        v_shape = v.get_shape().as_list()\n","        if (len(v_shape) > 2):\n","            Delta += 2.0*tf.reduce_max(tf.abs(tf.reduce_sum(v, axis=[1, 2])))\n","        else:\n","            Delta += 2.0*tf.reduce_max(tf.abs(tf.reduce_sum(v, axis=[1])))\n","        return Delta\n","    \n","    def generateNoise(n_in, epsilon, batch_size, test = False):\n","        Delta = 0.0;\n","        if test == True: # do not inject noise in the test phase\n","            Delta = 0.0;\n","        else:\n","            Delta = 10*(n_in + 1/4 * n_in**2); # global sensitivity for the output layer, note that 10 is the number of classes of the output layer\n","        # Generate the Laplace noise\n","        perturbFM = np.random.laplace(0.0, Delta/(epsilon*batch_size), n_in)\n","        perturbFM = np.reshape(perturbFM, [n_in]);\n","        return perturbFM;\n","\n","    def pretrain(self, sess, X_train, batch_size=3600, pretraining_epochs=3, lr=0.1, k=1,\n","                    display_step=1):\n","        '''\n","        Pretrain the layers (just train the Convolutional RBM layers)\n","        :param sess: tf.Session\n","        :param X_train: the input of the train set (You might modify this function if you do not use the designed mnist)\n","        :param batch_size: int\n","        :param lr: float\n","        :param k: int, use CD-k\n","        :param pretraining_epoch: int\n","        :param display_step: int\n","        '''\n","        print('Starting pretraining...\\n')\n","        start_time = timeit.default_timer()\n","        batch_num = int(math.ceil(X_train.test.num_examples / batch_size)) # The number of batch per epoch  -----------------------\n","        # Pretrain layer by layer\n","        for i in range(self.n_layers-1):\n","            # Get the cost of the current Convolutional RBM layer\n","            cost = self.layers[i].cost;\n","            # Get the objective function of the current Convolutional RBM layer\n","            train_ops = self.pretrain_ops[i]\n","            # Get the Delta operation of the current Convolutional RBM layer\n","            delta = self.getDelta(v = self.layers[i].input, W = self.layers[i].W, b = self.layers[i].b)\n","            for epoch in range(pretraining_epochs):\n","                avg_cost = 0.0\n","                for j in range(batch_num):\n","                    x_batch, _ = X_train.test.next_batch(batch_size)  #------------------------------\n","                    # Compute the actual Delta with the current parameters of the current Convolutional RBM layer\n","                    _Delta = delta.eval(session=sess, feed_dict={self.x: x_batch});\n","                    #print(np.reshape(_Delta, [1]))\n","                    # training\n","                    sess.run(train_ops, feed_dict={self.x: x_batch, self.Delta: np.reshape(_Delta, [1])})\n","                    # cost\n","                    avg_cost += sess.run(cost, feed_dict={self.x: x_batch, self.Delta: np.reshape(_Delta, [1])}) / batch_num\n","                # print out the average cost every display_step\n","                if epoch % display_step == 0:\n","                    print(\"\\tPretraing layer {0} Epoch {1} cost: {2}\".format(i, epoch, avg_cost))\n","\n","        end_time = timeit.default_timer()\n","        print(\"\\nThe pretraining process ran for {0} minutes\".format((end_time - start_time) / 60))\n","    \n","    def finetuning(self, sess, trainSet, training_epochs=200, _epsilon = 0.25, _batch_size = 3600, display_step=10):\n","        '''\n","        Finetuing the network\n","        '''\n","        print(\"\\nStart finetuning...\\n\")\n","        start_time = timeit.default_timer()\n","        \n","        for epoch in range(training_epochs):\n","            #avg_cost = 0.0\n","            batch_num = int(math.ceil(trainSet.test.num_examples / _batch_size)) # The number of batch per epoch  ----------------------------\n","            for i in range(batch_num):\n","                x_batch, y_batch = trainSet.test.next_batch(_batch_size)  #----------------------\n","                # training\n","                LapNoise = pCDBN.generateNoise(n_in = 25, epsilon = _epsilon, batch_size = _batch_size, test = False); #Add Laplace noise in training\n","                sess.run(self.train_op, feed_dict={self.x: x_batch, self.y: y_batch, self.LaplaceNoise: LapNoise})\n","            # print out the average cost\n","            if epoch % display_step == 0:\n","                LapNoise = pCDBN.generateNoise(n_in = 25, epsilon = _epsilon, batch_size = _batch_size, test = True); #Do not add noise when testing\n","                val_acc = sess.run(self.accuracy, feed_dict={self.x: trainSet.validation.images, self.y: trainSet.validation.labels, self.LaplaceNoise: LapNoise}) #--------\n","                print(\"\\tEpoch {0} \\t validation accuacy: \\t {1}\".format(epoch, val_acc))\n","                x_a.append(epoch)\n","                y_a.append(val_acc)\n","                #plt.plot(epoch, val_acc, 'ro')\n","                #print(val_acc)\n","                #ax.plot(epoch, val_acc)\n","        end_time = timeit.default_timer()\n","        print(\"\\nThe finetuning process ran for {0} minutes\".format((end_time - start_time) / 60))\n","        plt.plot(x_a,y_a)\n","        plt.title(\"Epochs vs Val_accuracy\")\n","        plt.xlabel(\"Training epochs\")\n","        plt.ylabel(\"Val_accuracy\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9-x15TMK_zK9"},"outputs":[],"source":["if __name__ == \"__main__\":\n","    # mnist examples\n","    mnist = read_data_sets(\"MNIST_data/\", one_hot=True)\n","    dbn = pCDBN(n_in=784, n_out=10, filter_size = 5, hidden_layers_sizes=[32, 64, 25, 25], epsilon = 0.2, _batch_size = 3600, finetuneLR = 2e-4)\n","    sess = tf.Session()\n","    init = tf.global_variables_initializer()\n","    sess.run(init)\n","    # set random_seed for the reproducibility\n","    tf.set_random_seed(seed=1111)\n","    dbn.pretrain(sess, X_train=mnist)\n","    dbn.finetuning(sess, _epsilon = dbn.epsilon, _batch_size = dbn.batch_size, trainSet=mnist)"]}],"metadata":{"colab":{"collapsed_sections":[],"name":"dp_19.ipynb","provenance":[],"authorship_tag":"ABX9TyNfw5jGFVZOERUd+Va30UUK"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}