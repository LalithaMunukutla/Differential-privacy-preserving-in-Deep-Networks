{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMaWcGQ0+ayQ9eD2CzY3xRh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LalithaMunukutla/Differential-privacy-preserving-in-Deep-Networks/blob/main/DP_Phase_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rioJN28RXQG0"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as f\n",
        "import numpy as np\n",
        "import torchvision\n",
        "import torch\n",
        "from torchvision import datasets, transforms\n",
        "from torch.autograd import Variable\n",
        "import tensorflow_datasets\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from timeit import default_timer\n",
        "import matplotlib\n",
        "matplotlib.use('Agg')           # noqa: E402\n",
        "import matplotlib.gridspec as gridspec\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class DataLoader:\n",
        "    def __init__(self):\n",
        "        self.train_data = np.zeros(1)\n",
        "\n",
        "    def get_mnist(self):\n",
        "        self.train_data = torchvision.datasets.MNIST(root='../input/mnist/mnist/', train=True, transform=torchvision.transforms.ToTensor(), download=True,)\n",
        "\n",
        "    def get_train_data(self):\n",
        "        return self.train_data"
      ],
      "metadata": {
        "id": "KVACZG-2a6dV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DataLoader:\n",
        "    @staticmethod\n",
        "    def get_train_data(batch_size):\n",
        "        return torch.utils.data.DataLoader(datasets.MNIST('../data', train=True, download=True, transform=transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])), batch_size=batch_size, shuffle=True)\n",
        "\n",
        "    @staticmethod\n",
        "    def get_test_data(test_batch_size):\n",
        "        return torch.utils.data.DataLoader(datasets.MNIST('../data', train=False, transform=transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])), batch_size=test_batch_size, shuffle=True)"
      ],
      "metadata": {
        "id": "ZBks8BJucVzI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        self.conv1 = nn.Sequential(nn.Conv2d(in_channels=1, out_channels=16, kernel_size=5, stride=1, padding=2,), nn.ReLU(), nn.MaxPool2d(kernel_size=2),)\n",
        "        self.conv2 = nn.Sequential(nn.Conv2d(16, 32, 5, 1, 2), nn.ReLU(), nn.MaxPool2d(2),)\n",
        "        self.out = nn.Linear(32 * 7 * 7, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        output = self.out(x)\n",
        "        return output, x"
      ],
      "metadata": {
        "id": "a_ioifIycW28"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generateNoise(n_in, epsilon, batch_size, test = False):\n",
        "t    Delta = 0.0;\n",
        "    if test == True: # do not inject noise in the test phase\n",
        "        Delta = 0.0;\n",
        "    else:\n",
        "        Delta = 10*(n_in + 1/4 * n_in**2); # global sensitivity for the output layer, note that 10 is the number of classes of the output layer\n",
        "        # Generate the Laplace noise\n",
        "    perturbFM = np.random.laplace(0.0, Delta/(epsilon*batch_size), n_in)\n",
        "    perturbFM = np.reshape(perturbFM, [n_in]);\n",
        "    return perturbFM;"
      ],
      "metadata": {
        "id": "-a4CqW8qhze-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LSTM_network:\n",
        "\n",
        "    def __init__(self, n_hidden, embedding_dim, n_classes, weights=None, debug=False):\n",
        "        self.n_hidden = n_hidden\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.n_classes = n_classes\n",
        "        self.debug = debug\n",
        "\n",
        "        # model parameters\n",
        "        if weights is not None:\n",
        "            self.check_weights(weights)\n",
        "            self.W_x_fward = tf.constant(weights[0], dtype=tf.float64)\n",
        "            self.W_h_fward = tf.constant(weights[1], dtype=tf.float64)\n",
        "            self.b_fward = tf.constant(weights[2], dtype=tf.float64)\n",
        "\n",
        "            self.W_x_bward = tf.constant(weights[3], dtype=tf.float64)\n",
        "            self.W_h_bward = tf.constant(weights[4], dtype=tf.float64)\n",
        "            self.b_bward = tf.constant(weights[5], dtype=tf.float64)\n",
        "\n",
        "            self.W_dense_fw = tf.constant(weights[6][:self.n_hidden], dtype=tf.float64)\n",
        "            self.W_dense_bw = tf.constant(weights[6][self.n_hidden:], dtype=tf.float64)\n",
        "            self.b_dense = tf.constant(weights[7], dtype=tf.float64)\n",
        "        else:\n",
        "            self.W_x_fward = tf.constant(np.random.randn(self.embedding_dim, 4 * self.n_hidden))\n",
        "            self.W_h_fward = tf.constant(np.random.randn(self.n_hidden, 4 * self.n_hidden))\n",
        "            self.b_fward = tf.constant(np.random.randn(4*self.n_hidden,))\n",
        "\n",
        "            self.W_x_bward = tf.constant(np.random.randn(self.embedding_dim, 4 * self.n_hidden))\n",
        "            self.W_h_bward = tf.constant(np.random.randn(self.n_hidden, 4 * self.n_hidden))\n",
        "            self.b_bward = tf.constant(np.random.randn(4 * self.n_hidden, ))\n",
        "\n",
        "            self.W_dense_fw = tf.constant(np.random.randn(n_hidden, n_classes))\n",
        "            self.W_dense_bw = tf.constant(np.random.randn(n_hidden, n_classes))\n",
        "            self.b_dense = tf.constant(np.random.randn(n_classes))\n",
        "\n",
        "        # prediction of the net\n",
        "        self.y_hat = tf.Variable(0., shape=tf.TensorShape(None), dtype=tf.float64, name='y_hat')\n",
        "\n",
        "        # the following order is from keras. You might have to adjust it if you use different frameworks\n",
        "        self.idx_i = slice(0, self.n_hidden)\n",
        "        self.idx_f = slice(self.n_hidden, 2 * self.n_hidden)\n",
        "        self.idx_c = slice(2 * self.n_hidden, 3 * self.n_hidden)\n",
        "        self.idx_o = slice(3 * self.n_hidden, 4 * self.n_hidden)\n",
        "\n",
        "    def check_weights(self, weights):\n",
        "        assert len(weights) == 8\n",
        "        assert weights[0].shape == weights[3].shape == (self.embedding_dim, 4 * self.n_hidden)\n",
        "        assert weights[1].shape == weights[4].shape == (self.n_hidden, 4 * self.n_hidden)\n",
        "        assert weights[2].shape == weights[5].shape == (4 * self.n_hidden, )\n",
        "        assert weights[6].shape == (2 * self.n_hidden, self.n_classes)\n",
        "        assert weights[7].shape == (self.n_classes,)\n",
        "\n",
        "    # x is batch of embedding vectors (batch_size, embedding_dim)\n",
        "    @tf.function\n",
        "    def cell_step(self, x, h_old, c_old, W_x, W_h, b):\n",
        "        # fward pass\n",
        "        gate_x = tf.matmul(x, W_x)\n",
        "        gate_h = tf.matmul(h_old, W_h)\n",
        "        gate_pre = gate_x + gate_h + b\n",
        "        gate_post = tf.concat([tf.sigmoid(gate_pre[:, self.idx_i]), tf.sigmoid(gate_pre[:, self.idx_f]), tf.tanh(gate_pre[:, self.idx_c]), tf.sigmoid(gate_pre[:, self.idx_o]),], axis=1)\n",
        "        c_new = gate_post[:, self.idx_f] * c_old + gate_post[:, self.idx_i] * gate_post[:, self.idx_c]\n",
        "        h_new = gate_post[:, self.idx_o] * tf.tanh(c_new)\n",
        "        return gate_pre, gate_post, c_new, h_new\n",
        "\n",
        "    # x is batch of embedding vectors (batch_size, embedding_dim)\n",
        "    @tf.function\n",
        "    def one_step_fward(self, x, h_old_fw, c_old_fw):\n",
        "        fward = self.cell_step(x, h_old_fw, c_old_fw, self.W_x_fward, self.W_h_fward, self.b_fward)\n",
        "        return fward\n",
        "\n",
        "    # x_rev is batch of embedding vectors (batch_size, embedding_dim)\n",
        "    @tf.function\n",
        "    def one_step_bward(self, x_rev, h_old_bw, c_old_bw):\n",
        "        bward = self.cell_step(x_rev, h_old_bw, c_old_bw, self.W_x_bward, self.W_h_bward, self.b_bward)\n",
        "        return bward\n",
        "\n",
        "    # input is full batch (batch_size, T, embedding_dim)\n",
        "    @tf.function(experimental_relax_shapes=True)\n",
        "    def full_pass(self, x):\n",
        "        assert len(x.shape) == 3, '3 dimensional input required, got input of len {}'.format(len(x.shape))\n",
        "        batch_size = x.shape[0]\n",
        "        # we have to reorder the input since tf.scan scans the input along the first axis\n",
        "        elems = tf.transpose(x, perm=[1,0,2])\n",
        "        initializer = (tf.constant(np.zeros((batch_size, 4 * self.n_hidden))),  # gates_pre\n",
        "                       tf.constant(np.zeros((batch_size, 4 * self.n_hidden))),  # gates_post\n",
        "                       tf.constant(np.zeros((batch_size, self.n_hidden))),      # c_t\n",
        "                       tf.constant(np.zeros((batch_size, self.n_hidden))))      # h_t\n",
        "        fn_fward = lambda a, x: self.one_step_fward(x, a[3], a[2])\n",
        "        fn_bward = lambda a, x: self.one_step_bward(x, a[3], a[2])\n",
        "        # outputs contain tesnors with (T, gates_pre, gates_post, c,h)\n",
        "        o_fward = tf.scan(fn_fward, elems, initializer=initializer)\n",
        "        o_bward = tf.scan(fn_bward, elems, initializer=initializer, reverse=True)\n",
        "        # final prediction scores\n",
        "        y_fward = tf.matmul(o_fward[3][-1], self.W_dense_fw)\n",
        "        y_bward = tf.matmul(o_bward[3][0], self.W_dense_bw)\n",
        "        y_hat = y_fward + y_bward + self.b_dense\n",
        "        self.y_hat.assign(y_hat)\n",
        "        return y_hat, o_fward, o_bward\n",
        "\n",
        "    def lrp_linear_layer(self, h_in, w, b, hout, Rout, bias_nb_units, eps, bias_factor=0.0):\n",
        "        \"\"\"\n",
        "        LRP for a linear layer with input dim D and output dim M.\n",
        "        Args:\n",
        "        - hin:            forward pass input, of shape (batch_size, D)\n",
        "        - w:              connection weights, of shape (D, M)\n",
        "        - b:              biases, of shape (M,)\n",
        "        - hout:           forward pass output, of shape (batch_size, M) (unequal to np.dot(w.T,hin)+b if more than\n",
        "                          one incoming layer!)\n",
        "        - Rout:           relevance at layer output, of shape (batch_size, M)\n",
        "        - bias_nb_units:  total number of connected lower-layer units (onto which the bias/stabilizer contribution\n",
        "                          is redistributed for sanity check)\n",
        "        - eps:            stabilizer (small positive number)\n",
        "        - bias_factor:    set to 1.0 to check global relevance conservation, otherwise use 0.0 to ignore\n",
        "                          bias/stabilizer redistribution (recommended)\n",
        "        Returns:\n",
        "        - Rin:            relevance at layer input, of shape (batch_size, D)\n",
        "        \"\"\"\n",
        "        bias_factor_t = tf.constant(bias_factor, dtype=tf.float64)\n",
        "        eps_t = tf.constant(eps, dtype=tf.float64)\n",
        "        sign_out = tf.cast(tf.where(hout >= 0, 1., -1.), tf.float64)   # shape (batch_size, M)\n",
        "        numerator_1 = tf.expand_dims(h_in, axis=2) * w\n",
        "        numerator_2 = bias_factor_t * (tf.expand_dims(b, 0) + eps_t * sign_out) / bias_nb_units\n",
        "        # use the following term if you want to check relevance property\n",
        "        #numerator_2 =  (bias_factor_t * tf.expand_dims(b, 0) + eps_t * sign_out) / bias_nb_units\n",
        "        numerator = numerator_1 + tf.expand_dims(numerator_2, 1)\n",
        "        denom = hout + (eps*sign_out)\n",
        "        message = numerator / tf.expand_dims(denom, 1) * tf.expand_dims(Rout, 1)\n",
        "        R_in = tf.reduce_sum(message, axis=2)\n",
        "        return R_in\n",
        "\n",
        "    def lrp(self, x, y=None, eps=1e-3, bias_factor=0.0):\n",
        "        assert len(x.shape) == 3, '3 dimensional input required, got input of len {}'.format(len(x.shape))\n",
        "        lrp_pass = self.lrp_lstm(x,y,eps, bias_factor)\n",
        "        # add forward and backward relevances of x.\n",
        "        # Here we have to reverse R_x_fw since the tf.scan() function starts at the last timestep (T-1) and moves to\n",
        "        # timestep 0. Therefore the last entry of lrp_pass[2] belongs to the first timestep of x. Likewise, the last\n",
        "        # entry of lrp_pass[5] (R_x_rev) belongs to the last timestep of x and is thus already in the right order.\n",
        "        Rx_ = tf.reverse(lrp_pass[2], axis=[0]) + lrp_pass[5]\n",
        "        Rx = tf.transpose(Rx_, perm=(1,0,2))  # put batch dimension to first dim again\n",
        "        # remaining relevance is sum of last entry of Rh and Rc\n",
        "        rest = tf.reduce_sum(lrp_pass[0][-1] + lrp_pass[1][-1] + lrp_pass[3][-1] + lrp_pass[4][-1], axis=1)\n",
        "        return Rx, rest\n",
        "\n",
        "    @tf.function\n",
        "    def lrp_lstm(self, x, y=None, eps=1e-3, bias_factor=0.0):\n",
        "        batch_size = x.shape[0]\n",
        "        T = x.shape[1]\n",
        "        x_rev = tf.reverse(x, axis=[1])\n",
        "        # update inner states\n",
        "        y_hat, output_fw, output_bw = self.full_pass(x)\n",
        "        # if classes are given, use them. Else choose prediction of the network\n",
        "        if y is not None:\n",
        "            assert y.shape == (batch_size, )\n",
        "            if not y.dtype is tf.int64:\n",
        "                y = tf.cast(y, tf.int64)\n",
        "            R_out_mask = tf.one_hot(y, depth=self.n_classes, dtype=tf.float64)\n",
        "        else:\n",
        "            R_out_mask = tf.one_hot(tf.argmax(y_hat, axis=1), depth=self.n_classes, dtype=tf.float64)\n",
        "        R_T = y_hat * R_out_mask\n",
        "        gates_pre_fw, gates_post_fw, c_fw, h_fw = output_fw\n",
        "        gates_pre_bw, gates_post_bw, c_bw, h_bw = output_bw\n",
        "        # c and h have one timestep more than x (the initial one, we have to add these zeros manually)\n",
        "        zero_block = tf.constant(np.zeros((1, batch_size, self.n_hidden)))\n",
        "        c_fw = tf.concat([c_fw, zero_block], axis=0)\n",
        "        h_fw = tf.concat([h_fw, zero_block], axis=0)\n",
        "        gates_pre_bw = tf.reverse(gates_pre_bw, [0])\n",
        "        gates_post_bw = tf.reverse(gates_post_bw, [0])\n",
        "        c_bw = tf.reverse(c_bw, [0])\n",
        "        h_bw = tf.reverse(h_bw, [0])\n",
        "        c_bw = tf.concat([c_bw, zero_block], axis=0)\n",
        "        h_bw = tf.concat([h_bw, zero_block], axis=0)\n",
        "\n",
        "        # first calculate relevaces from final linear layer\n",
        "        Rh_fw_T = self.lrp_linear_layer(h_fw[T - 1], self.W_dense_fw, self.b_dense, y_hat, R_T, 2*self.n_hidden, eps, bias_factor)\n",
        "        Rh_bw_T = self.lrp_linear_layer(h_bw[T - 1], self.W_dense_bw, self.b_dense, y_hat, R_T, 2*self.n_hidden, eps, bias_factor)\n",
        "        #if self.debug:\n",
        "            #tf.print('Dense: Input relevance', tf.reduce_sum(R_T, axis=1))\n",
        "            #tf.print('Dense: Output relevance', tf.reduce_sum(Rh_fw_T+Rh_bw_T, axis=1))\n",
        "        elems = np.arange(T-1, -1, -1)\n",
        "        initializer = (\n",
        "                       Rh_fw_T,                                                                     # R_h_fw\n",
        "                       Rh_fw_T,                                                                     # R_c_fw\n",
        "                       tf.constant(np.zeros((batch_size, self.embedding_dim)), name='R_x_fw'),      # R_x_fw\n",
        "                       Rh_bw_T,                                                                     # R_h_bw\n",
        "                       Rh_bw_T,                                                                     # R_c_bw\n",
        "                       tf.constant(np.zeros((batch_size, self.embedding_dim)), name='R_x_bw')       # R_x_bw\n",
        "                       )\n",
        "        eye = tf.eye(self.n_hidden, dtype=tf.float64)\n",
        "        zeros_hidden = tf.constant(np.zeros((self.n_hidden)))\n",
        "\n",
        "        @tf.function\n",
        "        def update(input_tuple, t):\n",
        "            # t starts with T-1 ; the values we want to update are essentially Rh, Rc and Rx\n",
        "            # input_tuple is (R_h_fw_t+1, R_c_fw_t+1, R_x_fw_t+1, R_h_bw_t+1, R_h_bw_t+1, R_x_bw_t+1)\n",
        "            #forward\n",
        "            Rc_fw_t = self.lrp_linear_layer(gates_post_fw[t, :, self.idx_f] * c_fw[t-1, :], eye, zeros_hidden, c_fw[t, :],  input_tuple[1], 2*self.n_hidden, eps, bias_factor)\n",
        "            R_g_fw = self.lrp_linear_layer(gates_post_fw[t,:,self.idx_i] * gates_post_fw[t,:,self.idx_c], eye, zeros_hidden, c_fw[t, :], input_tuple[1], 2*self.n_hidden, eps, bias_factor)\n",
        "            #if self.debug:\n",
        "                #tf.print('Fw1: Input relevance', tf.reduce_sum(input_tuple[1], axis=1))\n",
        "                #tf.print('Fw1: Output relevance', tf.reduce_sum(Rc_fw_t + R_g_fw, axis=1))\n",
        "            Rx_t = self.lrp_linear_layer(x[:,t], self.W_x_fward[:, self.idx_c], self.b_fward[self.idx_c], gates_pre_fw[t, :, self.idx_c], R_g_fw, self.n_hidden + self.embedding_dim, eps, bias_factor)\n",
        "            Rh_fw_t = self.lrp_linear_layer(h_fw[t-1, :], self.W_h_fward[:, self.idx_c], self.b_fward[self.idx_c], gates_pre_fw[t, :, self.idx_c], R_g_fw, self.n_hidden + self.embedding_dim, eps, bias_factor)\n",
        "            #if self.debug:\n",
        "                #tf.print('Fw2: Input relevance', tf.reduce_sum(R_g_fw, axis=1))\n",
        "                #tf.print('Fw2: Output relevance', tf.reduce_sum(Rx_t,axis=1)+tf.reduce_sum(Rh_fw_t, axis=1))\n",
        "            if t != 0:\n",
        "                Rc_fw_t += Rh_fw_t\n",
        "            #backward\n",
        "            Rc_bw_t = self.lrp_linear_layer(gates_post_bw[t, :, self.idx_f] * c_bw[t-1, :], eye, zeros_hidden, c_bw[t, :], input_tuple[4], 2*self.n_hidden, eps, bias_factor)\n",
        "            R_g_bw = self.lrp_linear_layer(gates_post_bw[t, :, self.idx_i] * gates_post_bw[t, :, self.idx_c], eye, zeros_hidden, c_bw[t,:], input_tuple[4], 2*self.n_hidden, eps, bias_factor)\n",
        "            #if self.debug:\n",
        "                #tf.print('Bw1: Input relevance', tf.reduce_sum(input_tuple[4], axis=1))\n",
        "                #tf.print('Bw1: Output relevance', tf.reduce_sum(Rc_bw_t + R_g_bw, axis=1))\n",
        "            Rx_rev_t = self.lrp_linear_layer(x_rev[:, t], self.W_x_bward[:, self.idx_c], self.b_bward[self.idx_c], gates_pre_bw[t, :, self.idx_c], R_g_bw, self.n_hidden + self.embedding_dim, eps, bias_factor)\n",
        "            Rh_bw_t = self.lrp_linear_layer(h_bw[t-1, :], self.W_h_bward[:, self.idx_c], self.b_bward[self.idx_c], gates_pre_bw[t, :, self.idx_c], R_g_bw, self.n_hidden + self.embedding_dim, eps, bias_factor)\n",
        "            #if self.debug:\n",
        "                #tf.print('Bw2: Input relevance', tf.reduce_sum(R_g_bw, axis=1))\n",
        "                #tf.print('Bw2: Output relevance', tf.reduce_sum(Rx_rev_t,axis=1)+tf.reduce_sum(Rh_bw_t, axis=1))\n",
        "            if t != 0:\n",
        "                Rc_bw_t += Rh_bw_t\n",
        "            return Rh_fw_t, Rc_fw_t, Rx_t, Rh_bw_t, Rc_bw_t, Rx_rev_t\n",
        "\n",
        "        lrp_pass = tf.scan(update, elems, initializer)\n",
        "        return lrp_pass"
      ],
      "metadata": {
        "id": "lk0__wTGgJwh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CnnLstm(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CnnLstm, self).__init__()\n",
        "        self.cnn = CNN()\n",
        "        self.rnn=lrp_lstm()\n",
        "        #self.rnn = nn.LSTM(input_size=1568, hidden_size=64, num_layers=1, batch_first=True)\n",
        "        self.linear = nn.Linear(64, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch_size, time_steps, channels, height, width = x.size()\n",
        "        #print(\"x size:\")\n",
        "        #print(x.size())\n",
        "        c_in = x.view(batch_size * time_steps, channels, height, width)\n",
        "        #print(\"c_in size:\")\n",
        "        #print(c_in.size())\n",
        "        _, c_out = self.cnn(c_in)\n",
        "        #print(\"c_out size:\")\n",
        "        #print(c_out.size())\n",
        "        r_in = c_out.view(batch_size, time_steps, -1)\n",
        "        #print(\"r_in size:\")\n",
        "        #print(r_in.size())\n",
        "        r_out, (_, _) = self.rnn(r_in)\n",
        "        #print(\"r_out size:\")\n",
        "        #print(r_out.size())\n",
        "        r_out2 = self.linear(r_out[:, -1, :])\n",
        "        #print(\"r_out2 size:\")\n",
        "        #print(r_out2.size())\n",
        "        return f.log_softmax(r_out2, dim=1)"
      ],
      "metadata": {
        "id": "wiPwHr1ZcfOc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_a=[]\n",
        "y_a=[]\n",
        "class TrainCNNLSTM:\n",
        "    def __init__(self):\n",
        "        self.seed = 1\n",
        "        self.batch_size = 50\n",
        "        self.test_batch_size = 1000\n",
        "        self.epoch = 1\n",
        "        self.learning_rate = 0.01\n",
        "        self.step = 100\n",
        "        self.train_loader = None\n",
        "        self.test_loader = None\n",
        "        self.model = CnnLstm()\n",
        "\n",
        "    def load_data(self):\n",
        "        data_loader = DataLoader()\n",
        "        self.train_loader = data_loader.get_train_data(self.batch_size)\n",
        "        self.test_loader = data_loader.get_test_data(self.test_batch_size)\n",
        "\n",
        "    def train(self):\n",
        "        k=1\n",
        "        optimizer = torch.optim.SGD(self.model.parameters(), lr=self.learning_rate)\n",
        "        for iteration, (data, target) in enumerate(self.train_loader):\n",
        "            data = np.expand_dims(data, axis=1)\n",
        "            data = torch.FloatTensor(data)\n",
        "            data, target = Variable(data), Variable(target)\n",
        "            optimizer.zero_grad()\n",
        "            output = self.model(data)\n",
        "            loss = f.nll_loss(output, target)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            if iteration % self.step == 0:\n",
        "                print('Epoch: {} | train loss: {:.4f}'.format(self.epoch, loss.item()))\n",
        "                x_a.append(k)\n",
        "                k=k+1\n",
        "                y_a.append(loss.item())\n",
        "        plt.plot(x_a,y_a)\n",
        "        plt.title(\"Training steps vs Training loss\")\n",
        "        plt.xlabel(\"Training steps\")\n",
        "        plt.ylabel(\"Training loss\")\n",
        "    def test(self):\n",
        "        test_loss = 0\n",
        "        correct = 0\n",
        "        for data, target in self.test_loader:\n",
        "            data = np.expand_dims(data, axis=1)\n",
        "            data = torch.FloatTensor(data)\n",
        "            print(target.size)\n",
        "            data, target = Variable(data, volatile=True), Variable(target)\n",
        "            output = self.model(data)\n",
        "            test_loss += f.nll_loss(output, target, size_average=False).item()  # sum up batch loss\n",
        "            pred = torch.max(output, 1)[1].data.squeeze()\n",
        "            correct += pred.eq(target.data.view_as(pred)).long().cpu().sum()\n",
        "\n",
        "        test_loss /= len(self.test_loader.dataset)\n",
        "        print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(test_loss, correct, len(self.test_loader.dataset), 100. * correct / len(self.test_loader.dataset)))\n",
        "\n",
        "\n",
        "train = TrainCNNLSTM()\n",
        "train.load_data()\n",
        "train.train()\n",
        "train.test()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 729
        },
        "id": "B3BZdwU2ctuF",
        "outputId": "908bb1f2-d271-4781-e896-1318ff002bee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1 | train loss: 2.3160\n",
            "Epoch: 1 | train loss: 2.1378\n",
            "Epoch: 1 | train loss: 1.7555\n",
            "Epoch: 1 | train loss: 1.1408\n",
            "Epoch: 1 | train loss: 1.1242\n",
            "Epoch: 1 | train loss: 0.8596\n",
            "Epoch: 1 | train loss: 0.6117\n",
            "Epoch: 1 | train loss: 0.5239\n",
            "Epoch: 1 | train loss: 0.5043\n",
            "Epoch: 1 | train loss: 0.3807\n",
            "Epoch: 1 | train loss: 0.2640\n",
            "Epoch: 1 | train loss: 0.2940\n",
            "<built-in method size of Tensor object at 0x7f59aca375f0>\n",
            "<built-in method size of Tensor object at 0x7f59ab587d70>\n",
            "<built-in method size of Tensor object at 0x7f59abc07e90>\n",
            "<built-in method size of Tensor object at 0x7f59abbf5e90>\n",
            "<built-in method size of Tensor object at 0x7f59ab55c350>\n",
            "<built-in method size of Tensor object at 0x7f59abc07290>\n",
            "<built-in method size of Tensor object at 0x7f59aca378f0>\n",
            "<built-in method size of Tensor object at 0x7f59ab55c110>\n",
            "<built-in method size of Tensor object at 0x7f59abbf5ef0>\n",
            "<built-in method size of Tensor object at 0x7f59ac8b8bf0>\n",
            "\n",
            "Test set: Average loss: 0.3314, Accuracy: 9317/10000 (93%)\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nXa0f_xxc8Ny"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "__all__ = ['cw']\n",
        "\n",
        "\n",
        "def cw(model, x, y=None, eps=1.0, ord_=2, T=2, optimizer=tf.optimizers.Adam(learning_rate=0.1), alpha=0.9, min_prob=0, clip=(0.0, 1.0)):\n",
        "    xshape = x.get_shape().as_list()\n",
        "    noise = tf.get_variable('noise', xshape, tf.float32, initializer=tf.initializers.zeros)\n",
        "    x_scaled = (x - clip[0]) / (clip[1] - clip[0])\n",
        "    z = tf.clip_by_value(x_scaled, 1e-8, 1-1e-8)\n",
        "    xinv = tf.log(z / (1 - z)) / T\n",
        "    xadv = tf.sigmoid(T * (xinv + noise))\n",
        "    xadv = xadv * (clip[1] - clip[0]) + clip[0]\n",
        "    ybar, logits = model(xadv, logits=True)\n",
        "    ydim = ybar.get_shape().as_list()[1]\n",
        "    if y is not None:\n",
        "        y = tf.cond(tf.equal(tf.rank(y), 0), lambda: tf.fill([xshape[0]], y), lambda: tf.identity(y))\n",
        "    else:\n",
        "        y = tf.argmin(ybar, axis=1, output_type=tf.int32)\n",
        "    mask = tf.one_hot(y, ydim, on_value=0.0, off_value=float('inf'))\n",
        "    yt = tf.reduce_max(logits - mask, axis=1)\n",
        "    yo = tf.reduce_max(logits, axis=1)\n",
        "    loss0 = tf.nn.relu(yo - yt + min_prob)\n",
        "    axis = list(range(1, len(xshape)))\n",
        "    ord_ = float(ord_)\n",
        "    if 2 == ord_:\n",
        "        loss1 = tf.reduce_mean(tf.square(xadv-x))\n",
        "    else:\n",
        "        tau0 = tf.fill([xshape[0]] + [1]*len(axis), clip[1])\n",
        "        tau = tf.get_variable('cw8-noise-upperbound', dtype=tf.float32, initializer=tau0, trainable=False)\n",
        "        diff = xadv - x - tau\n",
        "        tau = alpha * tf.to_float(tf.reduce_all(diff < 0, axis=axis))\n",
        "        loss1 = tf.nn.relu(tf.reduce_sum(diff, axis=axis))\n",
        "    loss = eps*loss0 + loss1\n",
        "    train_op = optimizer.minimize(loss, var_list=[noise])\n",
        "    if 2 != ord_:\n",
        "        train_op = tf.group(train_op, tau)\n",
        "    return train_op, xadv, noise"
      ],
      "metadata": {
        "id": "zapJwaT3yQ6e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow.compat.v1 as tf\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
        "\n",
        "img_size = 28\n",
        "img_chan = 1\n",
        "n_classes = 10\n",
        "batch_size = 32\n",
        "\n",
        "class Timer(object):\n",
        "    def __init__(self, msg='Starting.....', timer=default_timer, factor=1, fmt=\"------- elapsed {:.4f}s --------\"):\n",
        "        self.timer = timer\n",
        "        self.factor = factor\n",
        "        self.fmt = fmt\n",
        "        self.end = None\n",
        "        self.msg = msg\n",
        "\n",
        "    def __call__(self):\n",
        "        return self.timer()\n",
        "\n",
        "    def __enter__(self):\n",
        "        print(self.msg)\n",
        "        self.start = self()\n",
        "        return self\n",
        "\n",
        "    def __exit__(self, exc_type, exc_value, exc_traceback):\n",
        "        self.end = self()\n",
        "        print(str(self))\n",
        "\n",
        "    def __repr__(self):\n",
        "        return self.fmt.format(self.elapsed)\n",
        "\n",
        "    @property\n",
        "    def elapsed(self):\n",
        "        if self.end is None:\n",
        "            return (self() - self.start) * self.factor\n",
        "        else:\n",
        "            return (self.end - self.start) * self.factor\n",
        "\n",
        "print('\\nLoading MNIST')\n",
        "\n",
        "mnist = tf.keras.datasets.mnist\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "X_train = np.reshape(X_train, [-1, img_size, img_size, img_chan])\n",
        "X_train = X_train.astype(np.float32) / 255\n",
        "X_test = np.reshape(X_test, [-1, img_size, img_size, img_chan])\n",
        "X_test = X_test.astype(np.float32) / 255\n",
        "to_categorical = tf.keras.utils.to_categorical\n",
        "y_train = to_categorical(y_train)\n",
        "y_test = to_categorical(y_test)\n",
        "\n",
        "print('\\nSpliting data')\n",
        "\n",
        "ind = np.random.permutation(X_train.shape[0])\n",
        "X_train, y_train = X_train[ind], y_train[ind]\n",
        "\n",
        "VALIDATION_SPLIT = 0.1\n",
        "n = int(X_train.shape[0] * (1-VALIDATION_SPLIT))\n",
        "X_valid = X_train[n:]\n",
        "X_train = X_train[:n]\n",
        "y_valid = y_train[n:]\n",
        "y_train = y_train[:n]\n",
        "\n",
        "print('\\nConstruction graph')\n",
        "\n",
        "\n",
        "def model(x, logits=False, training=False):\n",
        "    with tf.compat.v1.variable_scope('conv0', reuse=tf.AUTO_REUSE):\n",
        "        z = tf.layers.conv2d(x, filters=32, kernel_size=[3, 3], padding='same', activation=tf.nn.relu)\n",
        "        z = tf.layers.max_pooling2d(z, pool_size=[2, 2], strides=2)\n",
        "\n",
        "    with tf.compat.v1.variable_scope('conv1', reuse=tf.AUTO_REUSE):\n",
        "        z = tf.layers.conv2d(z, filters=64, kernel_size=[3, 3], padding='same', activation=tf.nn.relu)\n",
        "        z = tf.layers.max_pooling2d(z, pool_size=[2, 2], strides=2)\n",
        "\n",
        "    with tf.compat.v1.variable_scope('flatten', reuse=tf.AUTO_REUSE):\n",
        "        shape = z.get_shape().as_list()\n",
        "        z = tf.reshape(z, [-1, np.prod(shape[1:])])\n",
        "\n",
        "    with tf.compat.v1.variable_scope('mlp', reuse=tf.AUTO_REUSE):\n",
        "        z = tf.layers.dense(z, units=128, activation=tf.nn.relu)\n",
        "        z = tf.layers.dropout(z, rate=0.25, training=training)\n",
        "\n",
        "    logits_ = tf.layers.dense(z, units=10)\n",
        "    y = tf.nn.softmax(logits_, name='ybar')\n",
        "\n",
        "    if logits:\n",
        "        return y, logits_\n",
        "    return y\n",
        "\n",
        "class Dummy:\n",
        "    pass\n",
        "\n",
        "env = Dummy()\n",
        "\n",
        "with tf.compat.v1.variable_scope('model', reuse=tf.AUTO_REUSE):\n",
        "    env.x = tf.compat.v1.placeholder(tf.float32, (None, img_size, img_size, img_chan), name='x')\n",
        "    env.y = tf.compat.v1.placeholder(tf.float32, (None, n_classes), name='y')\n",
        "    env.training = tf.compat.v1.placeholder_with_default(False, (), name='mode')\n",
        "    env.ybar, logits = model(env.x, logits=True, training=env.training)\n",
        "    with tf.compat.v1.variable_scope('acc', reuse=tf.AUTO_REUSE):\n",
        "        count = tf.equal(tf.argmax(env.y, axis=1), tf.argmax(env.ybar, axis=1))\n",
        "        env.acc = tf.reduce_mean(tf.cast(count, tf.float32), name='acc')\n",
        "    with tf.compat.v1.variable_scope('loss', reuse=tf.AUTO_REUSE):\n",
        "        xent = tf.nn.softmax_cross_entropy_with_logits(labels=env.y, logits=logits)\n",
        "        env.loss = tf.reduce_mean(xent, name='loss')\n",
        "    with tf.compat.v1.variable_scope('train_op', reuse=tf.AUTO_REUSE):\n",
        "        optimizer = tf.train.AdamOptimizer()\n",
        "        vs = tf.global_variables()\n",
        "        env.train_op = optimizer.minimize(env.loss, var_list=vs)\n",
        "    env.saver = tf.train.Saver()\n",
        "    env.x_fixed = tf.placeholder(tf.float32, (batch_size, img_size, img_size, img_chan), name='x_fixed')\n",
        "    env.adv_eps = tf.placeholder(tf.float32, (), name='adv_eps')\n",
        "    env.adv_y = tf.placeholder(tf.int32, (), name='adv_y')\n",
        "    optimizer = tf.train.AdamOptimizer(learning_rate=0.1)\n",
        "    env.adv_train_op, env.xadv, env.noise = cw(model, env.x_fixed, y=env.adv_y, eps=env.adv_eps, optimizer=optimizer)\n",
        "\n",
        "print('\\nInitializing graph')\n",
        "\n",
        "env.sess = tf.InteractiveSession()\n",
        "env.sess.run(tf.global_variables_initializer())\n",
        "env.sess.run(tf.local_variables_initializer())\n",
        "\n",
        "\n",
        "def evaluate(env, X_data, y_data, batch_size=128):\n",
        "    print('\\nEvaluating')\n",
        "\n",
        "    n_sample = X_data.shape[0]\n",
        "    n_batch = int((n_sample+batch_size-1) / batch_size)\n",
        "    loss, acc = 0, 0\n",
        "\n",
        "    for batch in range(n_batch):\n",
        "        print(' batch {0}/{1}'.format(batch + 1, n_batch), end='\\r')\n",
        "        start = batch * batch_size\n",
        "        end = min(n_sample, start + batch_size)\n",
        "        cnt = end - start\n",
        "        batch_loss, batch_acc = env.sess.run([env.loss, env.acc], feed_dict={env.x: X_data[start:end], env.y: y_data[start:end]})\n",
        "        loss += batch_loss * cnt\n",
        "        acc += batch_acc * cnt\n",
        "    loss /= n_sample\n",
        "    acc /= n_sample\n",
        "    print(' loss: {0:.4f} acc: {1:.4f}'.format(loss, acc))\n",
        "    return loss, acc\n",
        "\n",
        "def train(env, X_data, y_data, X_valid=None, y_valid=None, epochs=1, load=False, shuffle=True, batch_size=128, name='model'):\n",
        "    if load:\n",
        "        if not hasattr(env, 'saver'):\n",
        "            return print('\\nError: cannot find saver op')\n",
        "        print('\\nLoading saved model')\n",
        "        return env.saver.restore(env.sess, 'model/{}'.format(name))\n",
        "    print('\\nTrain model')\n",
        "    n_sample = X_data.shape[0]\n",
        "    n_batch = int((n_sample+batch_size-1) / batch_size)\n",
        "    for epoch in range(epochs):\n",
        "        print('\\nEpoch {0}/{1}'.format(epoch + 1, epochs))\n",
        "        if shuffle:\n",
        "            print('\\nShuffling data')\n",
        "            ind = np.arange(n_sample)\n",
        "            np.random.shuffle(ind)\n",
        "            X_data = X_data[ind]\n",
        "            y_data = y_data[ind]\n",
        "        for batch in range(n_batch):\n",
        "            print(' batch {0}/{1}'.format(batch + 1, n_batch), end='\\r')\n",
        "            start = batch * batch_size\n",
        "            end = min(n_sample, start + batch_size)\n",
        "            env.sess.run(env.train_op, feed_dict={env.x: X_data[start:end], env.y: y_data[start:end], env.training: True})\n",
        "        if X_valid is not None:\n",
        "            evaluate(env, X_valid, y_valid)\n",
        "\n",
        "    if hasattr(env, 'saver'):\n",
        "        print('\\n Saving model')\n",
        "        os.makedirs('model', exist_ok=True)\n",
        "        env.saver.save(env.sess, 'model/{}'.format(name))\n",
        "\n",
        "\n",
        "def predict(env, X_data, batch_size=128):\n",
        "    print('\\nPredicting')\n",
        "    n_classes = env.ybar.get_shape().as_list()[1]\n",
        "    n_sample = X_data.shape[0]\n",
        "    n_batch = int((n_sample+batch_size-1) / batch_size)\n",
        "    yval = np.empty((n_sample, n_classes))\n",
        "    for batch in range(n_batch):\n",
        "        print(' batch {0}/{1}'.format(batch + 1, n_batch), end='\\r')\n",
        "        start = batch * batch_size\n",
        "        end = min(n_sample, start + batch_size)\n",
        "        y_batch = env.sess.run(env.ybar, feed_dict={env.x: X_data[start:end]})\n",
        "        yval[start:end] = y_batch\n",
        "    print()\n",
        "    return yval\n",
        "\n",
        "\n",
        "def make_cw(env, X_data, epochs=1, eps=0.1, batch_size=batch_size):\n",
        "    print('\\nMaking adversarials via CW')\n",
        "    n_sample = X_data.shape[0]\n",
        "    n_batch = int((n_sample + batch_size - 1) / batch_size)\n",
        "    X_adv = np.empty_like(X_data)\n",
        "    for batch in range(n_batch):\n",
        "        with Timer('Batch {0}/{1}   '.format(batch + 1, n_batch)):\n",
        "            end = min(n_sample, (batch+1) * batch_size)\n",
        "            start = end - batch_size\n",
        "            feed_dict = {env.x_fixed: X_data[start:end], env.adv_eps: eps, env.adv_y: np.random.choice(n_classes)}\n",
        "            env.sess.run(env.noise.initializer)\n",
        "            for epoch in range(epochs):\n",
        "                env.sess.run(env.adv_train_op, feed_dict=feed_dict)\n",
        "            xadv = env.sess.run(env.xadv, feed_dict=feed_dict)\n",
        "            X_adv[start:end] = xadv\n",
        "    return X_adv\n",
        "\n",
        "print('\\nTraining')\n",
        "\n",
        "train(env, X_train, y_train, X_valid, y_valid, load=False, epochs=5, name='mnist')\n",
        "\n",
        "print('\\nEvaluating on clean data')\n",
        "\n",
        "evaluate(env, X_test, y_test)\n",
        "\n",
        "print('\\nGenerating adversarial data')\n",
        "\n",
        "n_sample = 128\n",
        "ind = np.random.choice(X_test.shape[0], size=n_sample, replace=False)\n",
        "X_test = X_test[ind]\n",
        "y_test = y_test[ind]\n",
        "X_adv = make_cw(env, X_test, eps=0.002, epochs=100)\n",
        "\n",
        "print('\\nEvaluating on adversarial data')\n",
        "\n",
        "evaluate(env, X_adv, y_test)\n",
        "\n",
        "print('\\nRandomly sample adversarial data from each category')\n",
        "\n",
        "y1 = predict(env, X_test)\n",
        "y2 = predict(env, X_adv)\n",
        "z0 = np.argmax(y_test, axis=1)\n",
        "z1 = np.argmax(y1, axis=1)\n",
        "z2 = np.argmax(y2, axis=1)\n",
        "ind = np.logical_and(z0 == z1, z1 != z2)\n",
        "# print('success: ', np.sum(ind))\n",
        "ind = z0 == z1\n",
        "X_test = X_test[ind]\n",
        "X_adv = X_adv[ind]\n",
        "z1 = z1[ind]\n",
        "z2 = z2[ind]\n",
        "y2 = y2[ind]\n",
        "ind, = np.where(z1 != z2)\n",
        "cur = np.random.choice(ind, size=n_classes)\n",
        "X_org = np.squeeze(X_test[cur])\n",
        "X_tmp = np.squeeze(X_adv[cur])\n",
        "y_tmp = y2[cur]\n",
        "fig = plt.figure(figsize=(n_classes+0.2, 3.2))\n",
        "gs = gridspec.GridSpec(3, n_classes+1, width_ratios=[1]*n_classes + [0.1], wspace=0.01, hspace=0.01)\n",
        "label = np.argmax(y_tmp, axis=1)\n",
        "proba = np.max(y_tmp, axis=1)\n",
        "\n",
        "for i in range(n_classes):\n",
        "    ax = fig.add_subplot(gs[0, i])\n",
        "    ax.imshow(X_org[i], cmap='gray', interpolation='none')\n",
        "    ax.set_xticks([])\n",
        "    ax.set_yticks([])\n",
        "    ax = fig.add_subplot(gs[1, i])\n",
        "    img = ax.imshow(X_tmp[i]-X_org[i], cmap='RdBu_r', vmin=-1, vmax=1, interpolation='none')\n",
        "    ax.set_xticks([])\n",
        "    ax.set_yticks([])\n",
        "    ax = fig.add_subplot(gs[2, i])\n",
        "    ax.imshow(X_tmp[i], cmap='gray', interpolation='none')\n",
        "    ax.set_xticks([])\n",
        "    ax.set_yticks([])\n",
        "    ax.set_xlabel('{0} ({1:.2f})'.format(label[i], proba[i]), fontsize=12)\n",
        "\n",
        "ax = fig.add_subplot(gs[1, n_classes])\n",
        "dummy = plt.cm.ScalarMappable(cmap='RdBu_r', norm=plt.Normalize(vmin=-1, vmax=1))\n",
        "dummy.set_array([])\n",
        "fig.colorbar(mappable=dummy, cax=ax, ticks=[-1, 0, 1], ticklocation='right')\n",
        "\n",
        "print('\\nSaving figure')\n",
        "\n",
        "gs.tight_layout(fig)\n",
        "os.makedirs('img', exist_ok=True)\n",
        "plt.savefig('img/cw2_mnist.png')"
      ],
      "metadata": {
        "id": "ltxnzwLUoKvQ",
        "outputId": "1771088c-bb7a-4228-b83a-eb5b92a20688",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Loading MNIST\n",
            "\n",
            "Spliting data\n",
            "\n",
            "Construction graph\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:99: UserWarning: `tf.layers.conv2d` is deprecated and will be removed in a future version. Please Use `tf.keras.layers.Conv2D` instead.\n",
            "/usr/local/lib/python3.7/dist-packages/keras/legacy_tf_layers/convolutional.py:575: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
            "  return layer.apply(inputs)\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:100: UserWarning: `tf.layers.max_pooling2d` is deprecated and will be removed in a future version. Please use `tf.keras.layers.MaxPooling2D` instead.\n",
            "/usr/local/lib/python3.7/dist-packages/keras/legacy_tf_layers/pooling.py:600: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
            "  return layer.apply(inputs)\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:104: UserWarning: `tf.layers.conv2d` is deprecated and will be removed in a future version. Please Use `tf.keras.layers.Conv2D` instead.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:105: UserWarning: `tf.layers.max_pooling2d` is deprecated and will be removed in a future version. Please use `tf.keras.layers.MaxPooling2D` instead.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:112: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
            "/usr/local/lib/python3.7/dist-packages/keras/legacy_tf_layers/core.py:261: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
            "  return layer.apply(inputs)\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:113: UserWarning: `tf.layers.dropout` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dropout` instead.\n",
            "/usr/local/lib/python3.7/dist-packages/keras/legacy_tf_layers/core.py:413: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
            "  return layer.apply(inputs, training=training)\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:115: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Initializing graph\n",
            "\n",
            "Training\n",
            "\n",
            "Train model\n",
            "\n",
            "Epoch 1/5\n",
            "\n",
            "Shuffling data\n",
            "\n",
            "Evaluating\n",
            " loss: 0.0686 acc: 0.9768\n",
            "\n",
            "Epoch 2/5\n",
            "\n",
            "Shuffling data\n",
            "\n",
            "Evaluating\n",
            " loss: 0.0453 acc: 0.9863\n",
            "\n",
            "Epoch 3/5\n",
            "\n",
            "Shuffling data\n",
            " batch 422/422\n",
            "Evaluating\n",
            " loss: 0.0414 acc: 0.9877\n",
            "\n",
            "Epoch 4/5\n",
            "\n",
            "Shuffling data\n",
            " batch 422/422\n",
            "Evaluating\n",
            " loss: 0.0388 acc: 0.9888\n",
            "\n",
            "Epoch 5/5\n",
            "\n",
            "Shuffling data\n",
            " batch 422/422\n",
            "Evaluating\n",
            " loss: 0.0346 acc: 0.9908\n",
            "\n",
            " Saving model\n",
            "\n",
            "Evaluating on clean data\n",
            "\n",
            "Evaluating\n",
            " loss: 0.0255 acc: 0.9918\n",
            "\n",
            "Generating adversarial data\n",
            "\n",
            "Making adversarials via CW\n",
            "Batch 1/4   \n",
            "------- elapsed 3.6551s --------\n",
            "Batch 2/4   \n",
            "------- elapsed 3.5734s --------\n",
            "Batch 3/4   \n",
            "------- elapsed 3.5278s --------\n",
            "Batch 4/4   \n",
            "------- elapsed 3.5394s --------\n",
            "\n",
            "Evaluating on adversarial data\n",
            "\n",
            "Evaluating\n",
            " loss: 0.1014 acc: 0.9766\n",
            "\n",
            "Randomly sample adversarial data from each category\n",
            "\n",
            "Predicting\n",
            " batch 1/1\n",
            "\n",
            "Predicting\n",
            " batch 1/1\n",
            "\n",
            "Saving figure\n"
          ]
        }
      ]
    }
  ]
}